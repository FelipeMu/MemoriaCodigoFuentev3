{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Librerias para trabajar con la red neuronal y procesamiento de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # type: ignore\n",
    "import scipy.io\n",
    "from scipy.io import loadmat # type: ignore\n",
    "import tensorflow as tf # Para red neuronal profunda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time # Para tomar el tiempo de entrenamiento de la red\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONVERTIR MATRICES DE: .mat  --> .npy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Directorios de entrada y salida: ***SUJETOS SANOS Y PACIENTES TEC***\n",
    "\n",
    "**(1) sujetos sanos:** 1_HEMU - 2_DAOC - 3_DASI - 4_DABA - 5_HEFU - 6_JOBO - 7_ROMI - 8_FEGA - 9_GAGO - 10_MIMO - 11_JULE - 12_NIGA - 13_BYLA - 14_ARVA - 15_CLSE - 16_PAAR - 17_VATO - 18_FEBE - 19_VINA - 20_CLHE - 21_MAIN - 22_ALSA - 23_MIRA - 24_LACA - 25_GOAC - 26_ANGL - 27_HC036101\n",
    "___________________________________________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "**(2) pacientes tec:** 1_DENI1005 - 2_KNOW1001 - 3_ALI0 - 4_BUTL - 5_HAGG - 6_HASTI007 - 7_BOAM - 8_DANE0005 - 9_GREG - 10_AITK - 11_RANS0000 - 12_JONES004 - 13_PERR - 14_SLAC - 15_HEPPL010 - 16_RICHS010 - 17_KENT0007 - 18_STAN1002 - 19_MCDON022 - 20_PULL - 21_MORR1002 - 22_PARK - 23_HIGH - 24_NOBL - 25_COWL - 26_KHAN - 27_NOLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS/1_HEMU/PAMnoises_matrixcomplex_mat\n",
      "D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS/1_HEMU/VSCdnoises_matrixcomplex_mat\n",
      "D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS/1_HEMU/VSCinoises_matrixcomplex_mat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Directorios de las matrices complejas (coeficientes) de las senales PAM ,VSCd y VSCi de suejtos sanos o pacientes con tec. Se debe modificar estos directorios para ir\n",
    "# generando los respectivos modelos de cada individuo.\n",
    "\n",
    "# DIRECTORIOS: SUJETO SANO\n",
    "\n",
    "# SUJETO SANO O PACIENTE TEC POR ANALIZAR\n",
    "persona = '/1_HEMU'\n",
    "\n",
    " # INPUT PARA LA RED\n",
    "# INPUT PAM\n",
    "input_pam_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/PAMnoises_matrixcomplex_mat'\n",
    "# INPUT VSCd\n",
    "input_vscd_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/VSCdnoises_matrixcomplex_mat'\n",
    "# INPUT VSCI\n",
    "input_vsci_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/VSCinoises_matrixcomplex_mat'\n",
    "\n",
    "# OUTPUT O SALIDAS ESPERADAS PARA LA RED\n",
    "# OUTPUT PAM\n",
    "output_pam_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/PAMnoises_matrixcomplex_npy'\n",
    "# OUTPUT PAM\n",
    "output_vscd_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/VSCdnoises_matrixcomplex_npy'\n",
    "# OUTPUT PAM\n",
    "output_vsci_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/VSCinoises_matrixcomplex_npy'\n",
    "\n",
    "\n",
    "#######################################################################################################################################################\n",
    "#######################################################################################################################################################\n",
    "#######################################################################################################################################################\n",
    "\n",
    "\n",
    "# DIRECTORIOS: PACIENTE TEC\n",
    "#paciente_tec = '/1_DENI1005'\n",
    "\n",
    "\n",
    " # INPUT PARA LA RED\n",
    "# INPUT PAM\n",
    "#input_pam_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/TEC' + persona + '/PAMnoises_matrixcomplex_mat'\n",
    "# INPUT VSCd\n",
    "#input_vscd_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/TEC' + persona + '/VSCdnoises_matrixcomplex_mat'\n",
    "# INPUT VSCI\n",
    "#input_vsci_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/TEC' + persona + '/VSCinoises_matrixcomplex_mat'\n",
    "\n",
    "# OUTPUT O SALIDAS ESPERADAS PARA LA RED\n",
    "# OUTPUT PAM\n",
    "#output_pam_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/TEC' + persona + '/PAMnoises_matrixcomplex_npy'\n",
    "# OUTPUT PAM\n",
    "#output_vscd_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/TEC' + persona + '/VSCdnoises_matrixcomplex_npy'\n",
    "# OUTPUT PAM\n",
    "#output_vsci_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/TEC' + persona + '/VSCinoises_matrixcomplex_npy'\n",
    "\n",
    "\n",
    "print(input_pam_dir)\n",
    "print(input_vscd_dir)\n",
    "print(input_vsci_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear los directorios de salida si no existen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_pam_dir, exist_ok=True) # DIRECTORIO PARA GUARDAR MATRICES COMPLEJAS DE PAM EN FORMATO .npy\n",
    "os.makedirs(output_vscd_dir, exist_ok=True) # DIRECTORIO PARA GUARDAR MATRICES COMPLEJAS DE VSCd EN FORMATO .npy\n",
    "os.makedirs(output_vsci_dir, exist_ok=True) # DIRECTORIO PARA GUARDAR MATRICES COMPLEJAS DE VSCi EN FORMATO .npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para convertir archivos .mat a .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de archivos a analizar ->  50\n"
     ]
    }
   ],
   "source": [
    "total_files=sum(1 for filename in os.listdir(input_pam_dir) if filename.endswith('.mat')) + 1\n",
    "print(\"Total de archivos a analizar -> \",total_files-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mat_to_npy(input_dir, output_dir, prefix):\n",
    "    for i in range(1, total_files):\n",
    "        mat_file = os.path.join(input_dir, f'{prefix}_noise_{i}.mat')\n",
    "        npy_file = os.path.join(output_dir, f'{prefix}_noise_{i}.npy')\n",
    "        \n",
    "        # Cargar el archivo .mat\n",
    "        mat_data = loadmat(mat_file)\n",
    "        \n",
    "        # Extraer la matriz compleja\n",
    "        matrix_key = [key for key in mat_data.keys() if not key.startswith('__')][0]\n",
    "        matrix = mat_data[matrix_key]\n",
    "        \n",
    "        # Guardar la matriz en formato .npy\n",
    "        np.save(npy_file, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir archivos .mat a .npy para PAM y VSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_mat_to_npy(input_pam_dir, output_pam_dir, 'matrix_complex_pam')\n",
    "convert_mat_to_npy(input_vscd_dir, output_vscd_dir, 'matrix_complex_vscd')\n",
    "convert_mat_to_npy(input_vsci_dir, output_vsci_dir, 'matrix_complex_vsci')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversion a tensor tridimensional** (Estructura adecuada para entrenar la red U-net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios salida para matrices con estructura tensor tridimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pam_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/PAMnoises_matrixcomplex_npy'\n",
    "input_vscd_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/VSCdnoises_matrixcomplex_npy'\n",
    "input_vsci_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/VSCinoises_matrixcomplex_npy'\n",
    "\n",
    "output_pam_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/PAMnoises_matrixcomplex_npy_tensor3d'\n",
    "output_vscd_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/VSCdnoises_matrixcomplex_npy_tensor3d'\n",
    "output_vsci_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/VSCinoises_matrixcomplex_npy_tensor3d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear directorios de salida si no existen (matrices complejas en forma de tensor tridimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_pam_dir, exist_ok=True)\n",
    "os.makedirs(output_vscd_dir, exist_ok=True)\n",
    "os.makedirs(output_vsci_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####################################################\n",
    "PREPROCESAMIENTO ANTES DE NORMALIZACIÓN DE MATRICES\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CÁLCULO DE LA MEDIA - PAM & VSC (la media se calcula teniendo en cuenta todas las matrices)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acumuladores para calcular la media de cada matriz (real e imaginaria) y la desviacion estandar\n",
    "\n",
    "#==========================\n",
    "#=== PAM SIGNAl ===========\n",
    "#==========================\n",
    "#===\n",
    "# Para media\n",
    "#===\n",
    "sumatoria_real_pam = 0\n",
    "media_real_pam = 0\n",
    "\n",
    "sumatoria_imag_pam = 0\n",
    "media_imag_pam = 0\n",
    "#===\n",
    "# Para la desviacion estandar\n",
    "#===\n",
    "sumatoria_real_cuadrada_pam = 0\n",
    "sumatoria_imag_cuadrada_pam = 0\n",
    "\n",
    "desv_real_pam = 0\n",
    "desv_imag_pam = 0\n",
    "\n",
    "\n",
    "#==========================\n",
    "#=== VSC SIGNAl ===========\n",
    "#==========================\n",
    "#===\n",
    "# Para media\n",
    "#===\n",
    "sumatoria_real_vsc = 0\n",
    "media_real_vsc = 0\n",
    "\n",
    "sumatoria_imag_vsc = 0\n",
    "media_imag_vsc = 0\n",
    "#===\n",
    "# Para la desviacion estandar\n",
    "#===\n",
    "sumatoria_real_cuadrada_vsc = 0\n",
    "sumatoria_imag_cuadrada_vsc = 0\n",
    "\n",
    "desv_real_vsc = 0\n",
    "desv_imag_vsc = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCIONES PARA EL CÁLCULO DE LA MEDIA Y DESVIACIÓN ESTÁNDAR PARA LAS SEÑALES [[  PAM  ]]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte real de una matriz compleja PAM)\n",
    "def sumatoria_acumulada_real_pam(matriz):\n",
    "    global sumatoria_real_pam\n",
    "    sumatoria_real_pam = sumatoria_real_pam + np.sum(matriz)\n",
    "    #print(sumatoria_real_pam)\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_cuadrada_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices PAM.\n",
    "def sumatoria_acumulada_real_cuadrada_pam(matriz):\n",
    "    global sumatoria_real_cuadrada_pam, media_real_pam\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_real_cuadrada_pam = sumatoria_real_cuadrada_pam + (elemento - media_real_pam)**2\n",
    "\n",
    "\n",
    "#=====================================================================================================================================================\n",
    "#=====================================================================================================================================================\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte imaginaria de una matriz compleja PAM)\n",
    "def sumatoria_acumulada_imag_pam(matriz):\n",
    "    global sumatoria_imag_pam\n",
    "    sumatoria_imag_pam = sumatoria_imag_pam + np.sum(matriz)\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_cuadrada_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices PAM.\n",
    "def sumatoria_acumulada_imag_cuadrada_pam(matriz):\n",
    "    global sumatoria_imag_cuadrada_pam, media_imag_pam\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_imag_cuadrada_pam = sumatoria_imag_cuadrada_pam + (elemento - media_imag_pam)**2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCIONES PARA EL CÁLCULO DE LA MEDIA Y DESVIACIÓN ESTÁNDAR PARA LAS SEÑALES [[  VSC  ]]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte real de una matriz compleja VSC)\n",
    "def sumatoria_acumulada_real_vsc(matriz):\n",
    "    global sumatoria_real_vsc\n",
    "    sumatoria_real_vsc = sumatoria_real_vsc + np.sum(matriz)\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_cuadrada_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices VSC.\n",
    "def sumatoria_acumulada_real_cuadrada_vsc(matriz):\n",
    "    global sumatoria_real_cuadrada_vsc, media_real_vsc\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_real_cuadrada_vsc = sumatoria_real_cuadrada_vsc + (elemento - media_real_vsc)**2\n",
    "\n",
    "\n",
    "#=====================================================================================================================================================\n",
    "#=====================================================================================================================================================\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte imaginaria de una matriz compleja VSC)\n",
    "def sumatoria_acumulada_imag_vsc(matriz):\n",
    "    global sumatoria_imag_vsc\n",
    "    sumatoria_imag_vsc = sumatoria_imag_vsc + np.sum(matriz)\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_cuadrada_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices VSC.\n",
    "def sumatoria_acumulada_imag_cuadrada_vsc(matriz):\n",
    "    global sumatoria_imag_cuadrada_vsc, media_imag_vsc\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_imag_cuadrada_vsc = sumatoria_imag_cuadrada_vsc + (elemento - media_imag_vsc)**2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES & CÁLCULO DE LA MEDIA  MATRIZ PAM (Presion Arterial Media)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_pam_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        #========\n",
    "        # Normalizacion de los matrices\n",
    "        #========\n",
    "        # Sumar todos los datos de las matrices\n",
    "        sumatoria_acumulada_real_pam(matriz_compleja.real) # para matriz real\n",
    "        sumatoria_acumulada_imag_pam(matriz_compleja.imag) # para matriz imaginaria\n",
    "\n",
    "\n",
    "\n",
    "# Se calcula la media real de matrices correspondientes a pam signals: Se suman cada unos de los coeficientes de cada matriz real pam (archivos x filas x columnas)\n",
    "num_files_input_pam_dir = sum(1 for filename in os.listdir(input_pam_dir) if filename.endswith('.npy'))\n",
    "filas_matriz, columnas_matriz = matriz_compleja.shape\n",
    "coefs_totales =  num_files_input_pam_dir * filas_matriz * columnas_matriz # N\n",
    "media_real_pam = sumatoria_real_pam / coefs_totales # MEDIA REAL\n",
    "media_imag_pam = sumatoria_imag_pam / coefs_totales # MEDIA IMAGINARIA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES Y CÁLCULO DE LA DESVIACIÓN ESTÁNDAR || MATRIZ PAM (Presion Arterial Media)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_pam_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz real\n",
    "        sumatoria_acumulada_real_cuadrada_pam(matriz_compleja.real)\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz imaginaria\n",
    "        sumatoria_acumulada_imag_cuadrada_pam(matriz_compleja.imag)\n",
    "\n",
    "# Se calcula de desviacion estandar de las matrices reales e imaginarias\n",
    "desv_real_pam = np.square(sumatoria_real_cuadrada_pam/coefs_totales)\n",
    "desv_imag_pam = np.square(sumatoria_imag_cuadrada_pam/coefs_totales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#==============================================================================================================================\n",
    "#==============================================================================================================================\n",
    "#=============================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES & CÁLCULO DE LA MEDIA MATRIZ VSC (Velocidad Sanguínea Cerebral)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        #========\n",
    "        # Normalizacion de los matrices\n",
    "        #========\n",
    "        # Sumar todos los datos de las matrices\n",
    "        sumatoria_acumulada_real_vsc(matriz_compleja.real) # para matriz real\n",
    "        sumatoria_acumulada_imag_vsc(matriz_compleja.imag) # para matriz imaginaria\n",
    "\n",
    "\n",
    "\n",
    "# Se calcula la media real de matrices correspondientes a vsc signals: Se suman cada unos de los coeficientes de cada matriz real vsc (archivos x filas x columnas)\n",
    "num_files_input_vsc_dir = sum(1 for filename in os.listdir(input_vsc_dir) if filename.endswith('.npy'))\n",
    "media_real_vsc = sumatoria_real_vsc / coefs_totales # MEDIA REAL\n",
    "media_imag_vsc = sumatoria_imag_vsc / coefs_totales # MEDIA IMAGINARIA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES Y CÁLCULO DE LA DESVIACIÓN ESTÁNDAR || MATRIZ VSC (Velocidad Sanguínea Cerebral)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz real\n",
    "        sumatoria_acumulada_real_cuadrada_vsc(matriz_compleja.real)\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz imaginaria\n",
    "        sumatoria_acumulada_imag_cuadrada_vsc(matriz_compleja.imag)\n",
    "\n",
    "# Se calcula de desviacion estandar de las matrices reales e imaginarias\n",
    "desv_real_vsc = np.square(sumatoria_real_cuadrada_vsc/coefs_totales)\n",
    "desv_imag_vsc = np.square(sumatoria_imag_cuadrada_vsc/coefs_totales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**APLICACIÓN DE NORMALIZACION A LAS MATRICES PAM Y VSC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############################################################\n",
    "**NORMALIZACION MIN-MAX**\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_real_pam = 1000000\n",
    "min_imag_pam = 1000000\n",
    "max_real_pam = -100\n",
    "max_imag_pam = -100\n",
    "\n",
    "min_real_vsc = 1000000\n",
    "min_imag_vsc = 1000000\n",
    "max_real_vsc = -100\n",
    "max_imag_vsc = -100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PAM: encontrar min y max de matrices reales e imaginarias\n",
    "def encontrar_min_pam(matriz):\n",
    "    global min_real_pam, min_imag_pam\n",
    "    if np.min(matriz.real) < min_real_pam:\n",
    "        min_real_pam = np.min(matriz.real)\n",
    "\n",
    "    if np.min(matriz.imag) < min_imag_pam:\n",
    "        min_imag_pam = np.min(matriz.imag)\n",
    "\n",
    "\n",
    "def encontrar_max_pam(matriz):\n",
    "    global max_real_pam, max_imag_pam\n",
    "    if np.max(matriz.real) > max_real_pam:\n",
    "        max_real_pam = np.max(matriz.real)\n",
    "\n",
    "    if np.max(matriz.imag) > max_imag_pam:\n",
    "        max_imag_pam = np.max(matriz.imag)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "\n",
    "\n",
    "#VSC: encontrar min y max de matrices reales e imaginarias\n",
    "\n",
    "def encontrar_min_vsc(matriz):\n",
    "    global min_real_vsc, min_imag_vsc\n",
    "    if np.min(matriz.real) < min_real_vsc:\n",
    "        min_real_vsc = np.min(matriz.real)\n",
    "\n",
    "    if np.min(matriz.imag) < min_imag_vsc:\n",
    "        min_imag_vsc = np.min(matriz.imag)\n",
    "\n",
    "\n",
    "def encontrar_max_vsc(matriz):\n",
    "    global max_real_vsc, max_imag_vsc\n",
    "    if np.max(matriz.real) > max_real_vsc:\n",
    "        max_real_vsc = np.max(matriz.real)\n",
    "\n",
    "    if np.max(matriz.imag) > max_imag_vsc:\n",
    "        max_imag_vsc = np.max(matriz.imag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING MIN-MAX\n",
    "#PAM\n",
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Iterando sobre todas las matrices para encontrar el min y max\n",
    "        encontrar_min_pam(matriz_compleja)\n",
    "        encontrar_max_pam(matriz_compleja)\n",
    "\n",
    "#VSC\n",
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Iterando sobre todas las matrices para encontrar el min y max\n",
    "        encontrar_min_vsc(matriz_compleja)\n",
    "        encontrar_max_vsc(matriz_compleja)\n",
    "        \n",
    "\n",
    "print(min_real_pam)\n",
    "print(min_imag_pam)\n",
    "print(max_real_pam)\n",
    "print(max_imag_pam)\n",
    "\n",
    "print(\"------------\")\n",
    "\n",
    "print(min_real_vsc)\n",
    "print(min_imag_vsc)\n",
    "print(max_real_vsc)\n",
    "print(max_imag_vsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############################################################\n",
    "**NORMALIZACION Z-CORE**\n",
    "##############################################################\n",
    "z = (x - u) / desv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrada: matriz_compleja PAM (array bidimensional)\n",
    "#Salida: z_real (matriz real de pam normalizada), z_imag (matriz imag de pam normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz pam y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_pam(matriz_compleja):\n",
    "    global media_real_pam, media_imag_pam, desv_real_pam, desv_imag_pam\n",
    "    # Aplicacion de normalziacion z-core || z=(x - u)/desv\n",
    "    z_real = (matriz_compleja.real - media_real_pam) / desv_real_pam # normalizarcion parte real pam\n",
    "    z_imag = (matriz_compleja.imag - media_imag_pam) / desv_imag_pam # normalizacion parte imaginaria pam\n",
    "    return z_real, z_imag\n",
    "\n",
    "#Entrada: matriz_compleja PAM (array bidimensional)\n",
    "#Salida: z_real (matriz real de pam normalizada), z_imag (matriz imag de pam normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz pam y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_vsc(matriz_compleja):\n",
    "    global media_real_vsc, media_imag_vsc, desv_real_vsc, desv_imag_vsc\n",
    "    # Aplicacion de normalziacion z-core || z=(x - u)/desv\n",
    "    z_real = (matriz_compleja.real - media_real_vsc) / desv_real_vsc # normalizarcion parte real pam\n",
    "    z_imag = (matriz_compleja.imag - media_imag_vsc) / desv_imag_vsc # normalizacion parte imaginaria pam\n",
    "    return z_real, z_imag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NORMALIZACIÓN MEDIANTE MIN - MAX**<br>\n",
    "Ni = (Xi - Xmin) / (Xmax - Xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Entrada: matriz_compleja (array bidimensional de matriz PAM)\n",
    "#Salida: n_real (matriz real de pam normalizada), n_imag (matriz imag de pam normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz pam y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_minmax_pam(matriz_compleja):\n",
    "    global min_real_pam, max_real_pam, min_imag_pam, max_imag_pam\n",
    "    n_real = (matriz_compleja.real - min_real_pam) / (max_real_pam - min_real_pam)\n",
    "    n_imag = (matriz_compleja.imag - min_imag_pam) / (max_imag_pam - min_imag_pam)\n",
    "    return n_real, n_imag\n",
    "\n",
    "\n",
    "#Entrada: matriz_compleja (array bidimensional de matriz VSC)\n",
    "#Salida: n_real (matriz real de vsc normalizada), n_imag (matriz imag de vsc normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz vsc y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_minmax_vsc(matriz_compleja):\n",
    "    global min_real_vsc, max_real_vsc,  min_imag_vsc, max_imag_vsc\n",
    "    n_real = (matriz_compleja.real - min_real_vsc) / (max_real_vsc - min_real_vsc)\n",
    "    n_imag = (matriz_compleja.imag - min_imag_vsc) / (max_imag_vsc - min_imag_vsc)\n",
    "    return n_real, n_imag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAR MATRICES SEGÚN UNA NORMALIZACIÓN Y ORGANIZAR DATOS PARA LA RED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Entrada: matriz_compleja (array bidimensional)\n",
    "#Salida: datos_organizados (tensor de datos de la matriz pam)\n",
    "#Descripcion: funcion encargada de normalizar cada matriz pam y definir el input para la red u-net\n",
    "def procesar_matriz_compleja_pam(matriz_compleja):\n",
    "    \n",
    "    # Aplicacion de normalziacion Z-CORE || z = (x - u) / desv\n",
    "    #norm_real, norm_imag = normalizacion_pam(matriz_compleja)\n",
    "\n",
    "    # Aplicacion de normalziacion MIN-MAX || Ni = (Xi - Xmin) / (Xmax - Xmin)\n",
    "    #norm_real, norm_imag = normalizacion_minmax_pam(matriz_compleja)\n",
    "\n",
    "    # Crear input adecuado\n",
    "    #datos_organizados = np.stack((norm_real, norm_imag), axis=-1)\n",
    "    datos_organizados = np.stack((matriz_compleja.real, matriz_compleja.imag), axis=-1)\n",
    "    return datos_organizados\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Entrada: matriz_compleja (array bidimensional)\n",
    "#Salida: datos_organizados (tensor de datos de la matriz vsc)\n",
    "#Descripcion: funcion encargada de normalizar cada matriz vsc y definir el input para la red u-net\n",
    "def procesar_matriz_compleja_vsc(matriz_compleja):\n",
    "    \n",
    "    # Aplicacion de normalziacion Z-CORE || z=(x - u)/desv\n",
    "    #norm_real, norm_imag = normalizacion_vsc(matriz_compleja)\n",
    "\n",
    "    # Aplicacion de normalziacion MIN-MAX || Ni = (Xi-Xmin)/(Xmax-Xmin)\n",
    "    #norm_real, norm_imag = normalizacion_minmax_vsc(matriz_compleja)\n",
    "    \n",
    "    # Crear input adecuado\n",
    "    #datos_organizados = np.stack((norm_real, norm_imag), axis=-1)\n",
    "    datos_organizados = np.stack((matriz_compleja.real, matriz_compleja.imag), axis=-1)\n",
    "    return datos_organizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAR MATRICES COMPLEJAS EN LA CARPETA input_pam_dir y procesar matrices mediante una normalización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        output_path = os.path.join(output_pam_dir, filename)\n",
    "        \n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        # Procesar la matriz compleja segun una normalizacion\n",
    "        datos_organizados = procesar_matriz_compleja_pam(matriz_compleja)\n",
    "        \n",
    "        # Guardar los datos procesados\n",
    "        np.save(output_path, datos_organizados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAR MATRICES COMPLEJAS EN LA CARPETA input_vscd_dir**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesamiento completado.\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(input_vscd_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        input_path = os.path.join(input_vscd_dir, filename)\n",
    "        output_path = os.path.join(output_vscd_dir, filename)\n",
    "        \n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        # Procesar la matriz compleja segun una normalizacion\n",
    "        datos_organizados = procesar_matriz_compleja_vsc(matriz_compleja)\n",
    "        \n",
    "        # Guardar los datos procesados\n",
    "        np.save(output_path, datos_organizados)\n",
    "        \n",
    "print(\"Procesamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAR MATRICES COMPLEJAS EN LA CARPETA input_vsci_dir**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesamiento completado.\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(input_vsci_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        input_path = os.path.join(input_vsci_dir, filename)\n",
    "        output_path = os.path.join(output_vsci_dir, filename)\n",
    "        \n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        # Procesar la matriz compleja segun una normalizacion\n",
    "        datos_organizados = procesar_matriz_compleja_vsc(matriz_compleja)\n",
    "        \n",
    "        # Guardar los datos procesados\n",
    "        np.save(output_path, datos_organizados)\n",
    "        \n",
    "print(\"Procesamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificacion de \"shape\" - matrices pam y vsc**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de salida a verificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pam_dir_check = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/PAMnoises_matrixcomplex_npy_tensor3d'\n",
    "output_vscd_dir_check = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/VSCdnoises_matrixcomplex_npy_tensor3d'\n",
    "output_vsci_dir_check = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/VSCinoises_matrixcomplex_npy_tensor3d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para verificar la forma de una matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_shape(directorio, nombre_archivo):\n",
    "    path = os.path.join(directorio, nombre_archivo)\n",
    "    matriz = np.load(path)\n",
    "    return matriz.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar la forma de un archivo de ejemplo en output_pam_dir_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de matrix_complex_pam_noise_1.npy en D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS/1_HEMU/PAMnoises_matrixcomplex_npy_tensor3d: (36, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "ejemplo_pam = os.listdir(output_pam_dir_check)[0]  # Obtener el primer archivo de la carpeta\n",
    "shape_pam = verificar_shape(output_pam_dir_check, ejemplo_pam)\n",
    "print(f\"Shape de {ejemplo_pam} en {output_pam_dir_check}: {shape_pam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar la forma de un archivo de ejemplo en output_vscd_dir_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de matrix_complex_vscd_noise_1.npy en D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS/1_HEMU/VSCdnoises_matrixcomplex_npy_tensor3d: (36, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "ejemplo_vscd = os.listdir(output_vscd_dir_check)[0]  # Obtener el primer archivo de la carpeta\n",
    "shape_vscd = verificar_shape(output_vscd_dir_check, ejemplo_vscd)\n",
    "print(f\"Shape de {ejemplo_vscd} en {output_vscd_dir_check}: {shape_vscd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar la forma de un archivo de ejemplo en output_vsci_dir_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de matrix_complex_vsci_noise_1.npy en D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS/1_HEMU/VSCinoises_matrixcomplex_npy_tensor3d: (36, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "ejemplo_vsci = os.listdir(output_vsci_dir_check)[0]  # Obtener el primer archivo de la carpeta\n",
    "shape_vsci = verificar_shape(output_vsci_dir_check, ejemplo_vsci)\n",
    "print(f\"Shape de {ejemplo_vsci} en {output_vsci_dir_check}: {shape_vsci}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                **|||Red Neuronal Profunda: U-net|||**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENAL PAM\n",
    "input_pam_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/PAMnoises_matrixcomplex_npy_tensor3d'\n",
    "\n",
    "# VSC LADO DERECHO\n",
    "output_vscd_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/VSCdnoises_matrixcomplex_npy_tensor3d'\n",
    "# VSC LADO IZQUIERDO\n",
    "output_vsci_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS' + persona + '/VSCinoises_matrixcomplex_npy_tensor3d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para cargar los archivos .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_files(input_dir):\n",
    "    files = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.npy')])\n",
    "     # verificar orden con que entrar los archivos en X e Y\n",
    "    file_names = [os.path.basename(f) for f in files]\n",
    "    print(f\"Archivos: {file_names}\\n\")\n",
    "    data = [np.load(f) for f in files]\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA DE DATOS DE ENTRADAS Y SALIDAS PARA LA RED (X: INPUTS; Y: OUTPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos: ['matrix_complex_pam_noise_1.npy', 'matrix_complex_pam_noise_10.npy', 'matrix_complex_pam_noise_11.npy', 'matrix_complex_pam_noise_12.npy', 'matrix_complex_pam_noise_13.npy', 'matrix_complex_pam_noise_14.npy', 'matrix_complex_pam_noise_15.npy', 'matrix_complex_pam_noise_16.npy', 'matrix_complex_pam_noise_17.npy', 'matrix_complex_pam_noise_18.npy', 'matrix_complex_pam_noise_19.npy', 'matrix_complex_pam_noise_2.npy', 'matrix_complex_pam_noise_20.npy', 'matrix_complex_pam_noise_21.npy', 'matrix_complex_pam_noise_22.npy', 'matrix_complex_pam_noise_23.npy', 'matrix_complex_pam_noise_24.npy', 'matrix_complex_pam_noise_25.npy', 'matrix_complex_pam_noise_26.npy', 'matrix_complex_pam_noise_27.npy', 'matrix_complex_pam_noise_28.npy', 'matrix_complex_pam_noise_29.npy', 'matrix_complex_pam_noise_3.npy', 'matrix_complex_pam_noise_30.npy', 'matrix_complex_pam_noise_31.npy', 'matrix_complex_pam_noise_32.npy', 'matrix_complex_pam_noise_33.npy', 'matrix_complex_pam_noise_34.npy', 'matrix_complex_pam_noise_35.npy', 'matrix_complex_pam_noise_36.npy', 'matrix_complex_pam_noise_37.npy', 'matrix_complex_pam_noise_38.npy', 'matrix_complex_pam_noise_39.npy', 'matrix_complex_pam_noise_4.npy', 'matrix_complex_pam_noise_40.npy', 'matrix_complex_pam_noise_41.npy', 'matrix_complex_pam_noise_42.npy', 'matrix_complex_pam_noise_43.npy', 'matrix_complex_pam_noise_44.npy', 'matrix_complex_pam_noise_45.npy', 'matrix_complex_pam_noise_46.npy', 'matrix_complex_pam_noise_47.npy', 'matrix_complex_pam_noise_48.npy', 'matrix_complex_pam_noise_49.npy', 'matrix_complex_pam_noise_5.npy', 'matrix_complex_pam_noise_50.npy', 'matrix_complex_pam_noise_6.npy', 'matrix_complex_pam_noise_7.npy', 'matrix_complex_pam_noise_8.npy', 'matrix_complex_pam_noise_9.npy']\n",
      "\n",
      "Archivos: ['matrix_complex_vscd_noise_1.npy', 'matrix_complex_vscd_noise_10.npy', 'matrix_complex_vscd_noise_11.npy', 'matrix_complex_vscd_noise_12.npy', 'matrix_complex_vscd_noise_13.npy', 'matrix_complex_vscd_noise_14.npy', 'matrix_complex_vscd_noise_15.npy', 'matrix_complex_vscd_noise_16.npy', 'matrix_complex_vscd_noise_17.npy', 'matrix_complex_vscd_noise_18.npy', 'matrix_complex_vscd_noise_19.npy', 'matrix_complex_vscd_noise_2.npy', 'matrix_complex_vscd_noise_20.npy', 'matrix_complex_vscd_noise_21.npy', 'matrix_complex_vscd_noise_22.npy', 'matrix_complex_vscd_noise_23.npy', 'matrix_complex_vscd_noise_24.npy', 'matrix_complex_vscd_noise_25.npy', 'matrix_complex_vscd_noise_26.npy', 'matrix_complex_vscd_noise_27.npy', 'matrix_complex_vscd_noise_28.npy', 'matrix_complex_vscd_noise_29.npy', 'matrix_complex_vscd_noise_3.npy', 'matrix_complex_vscd_noise_30.npy', 'matrix_complex_vscd_noise_31.npy', 'matrix_complex_vscd_noise_32.npy', 'matrix_complex_vscd_noise_33.npy', 'matrix_complex_vscd_noise_34.npy', 'matrix_complex_vscd_noise_35.npy', 'matrix_complex_vscd_noise_36.npy', 'matrix_complex_vscd_noise_37.npy', 'matrix_complex_vscd_noise_38.npy', 'matrix_complex_vscd_noise_39.npy', 'matrix_complex_vscd_noise_4.npy', 'matrix_complex_vscd_noise_40.npy', 'matrix_complex_vscd_noise_41.npy', 'matrix_complex_vscd_noise_42.npy', 'matrix_complex_vscd_noise_43.npy', 'matrix_complex_vscd_noise_44.npy', 'matrix_complex_vscd_noise_45.npy', 'matrix_complex_vscd_noise_46.npy', 'matrix_complex_vscd_noise_47.npy', 'matrix_complex_vscd_noise_48.npy', 'matrix_complex_vscd_noise_49.npy', 'matrix_complex_vscd_noise_5.npy', 'matrix_complex_vscd_noise_50.npy', 'matrix_complex_vscd_noise_6.npy', 'matrix_complex_vscd_noise_7.npy', 'matrix_complex_vscd_noise_8.npy', 'matrix_complex_vscd_noise_9.npy']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = load_npy_files(input_pam_dir) # inputs\n",
    "Y = load_npy_files(output_vscd_dir) # outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar las formas de los datos cargados (# entradas, filas, columnas, canales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de los inputs (X): (50, 36, 1024, 2)\n",
      "Shape de los outputs (Y): (50, 36, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape de los inputs (X): {X.shape}\")\n",
    "print(f\"Shape de los outputs (Y): {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la U-Net con regularizacion L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def unet_model_with_l2(input_shape, l2_lambda):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Regularizer\n",
    "    l2_reg = tf.keras.regularizers.l2(l2_lambda)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(inputs)\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(p1)\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(p2)\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c3)\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3)\n",
    "    u4 = tf.keras.layers.concatenate([u4, c2])\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(u4)\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c4)\n",
    "    \n",
    "    u5 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u5 = tf.keras.layers.concatenate([u5, c1])\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(u5)\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c5)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(2, (1, 1), activation='linear')(c5)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "'''\n",
    "\n",
    "def unet_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Regularizer\n",
    "    #l2_reg = tf.keras.regularizers.l2(l2_lambda)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs) #filtro original=64\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1) #filtro original=64\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1) #filtro original=128\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2) #filtro original=128\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2) #filtro original=256\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3) #filtro original=256\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3) #filtro original=128\n",
    "    u4 = tf.keras.layers.concatenate([u4, c2])\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u4) #filtro original=128\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4) #filtro original=128\n",
    "    \n",
    "    u5 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4) #filtro original=64\n",
    "    u5 = tf.keras.layers.concatenate([u5, c1])\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u5) #filtro original=64\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c5) #filtro original=64\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(2, (1, 1), activation='linear')(c5)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la metrica NMSE ajustada para utilizar la varianza de los valores verdaderos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmse(y_true, y_pred):\n",
    "    mse = tf.keras.backend.mean(tf.keras.backend.square(y_true - y_pred))\n",
    "    var_true = tf.keras.backend.var(y_true)\n",
    "    return mse / var_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**HIPERPARAMETROS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pasos de decaimiento -> 300 pasos.\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 300\n",
    "batchsize = 8\n",
    "learning_rate = 0.001\n",
    "#l2_lambda = 0.01\n",
    "validation_split = 0.3 # 70% entrenamiento & 30% validacion\n",
    "\n",
    "\n",
    " # alpha: el lr min al que llegara el decaimiento sera el 10% del lr inicia\n",
    "alpha = 0.1\n",
    "# decay steps: Numero de pasos de entrenamiento tras los cuales el learning rate decaera desde su valor inicial hasta el valor final determinado por alpha\n",
    "decay_steps = 300#(int(X.shape[0]/batchsize))*max_epoch \n",
    "print(\"Total pasos de decaimiento ->\",decay_steps, \"pasos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREACIÓN DEL MODELO U-NET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1:]  # forma del input a entrar. en este caso esta forma debe coincidir con las matrices que entran a la red tensor X = [#inputs, columnas, filas, canales]. Se omite #inputs\n",
    "model = unet_model(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEFINICION DE LA FUNCION DE DECAIMIENTO, ALGORITMO OPTIMIZADOR, FUNCION DE PERDIDA Y METRICA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion decaimiento de coseno\n",
    "decay_cosine = tf.keras.experimental.CosineDecay(learning_rate, decay_steps)\n",
    "def lr_schedule(X):\n",
    "    return float(decay_cosine(X))\n",
    "    \n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[nmse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################<br>\n",
    "#########################################################################################################<br>\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTRENAMIENTO DE LA RED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 35s 5s/step - loss: 0.3689 - nmse: 0.9115 - val_loss: 0.3135 - val_nmse: 0.8185\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3374 - nmse: 0.8286 - val_loss: 0.3035 - val_nmse: 0.7923\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.3274 - nmse: 0.8117 - val_loss: 0.2919 - val_nmse: 0.7619\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.3173 - nmse: 0.7857 - val_loss: 0.2804 - val_nmse: 0.7318\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.3019 - nmse: 0.7309 - val_loss: 0.2595 - val_nmse: 0.6763\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.3008 - nmse: 0.7458 - val_loss: 0.2821 - val_nmse: 0.7359\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.2977 - nmse: 0.7327 - val_loss: 0.2540 - val_nmse: 0.6617\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2779 - nmse: 0.6879 - val_loss: 0.2379 - val_nmse: 0.6191\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2590 - nmse: 0.6465 - val_loss: 0.2183 - val_nmse: 0.5672\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.2392 - nmse: 0.6005 - val_loss: 0.2116 - val_nmse: 0.5493\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.2259 - nmse: 0.5584 - val_loss: 0.1856 - val_nmse: 0.4802\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.2052 - nmse: 0.5035 - val_loss: 0.1695 - val_nmse: 0.4378\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1940 - nmse: 0.4639 - val_loss: 0.1538 - val_nmse: 0.3965\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1803 - nmse: 0.4480 - val_loss: 0.1470 - val_nmse: 0.3785\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1692 - nmse: 0.4172 - val_loss: 0.1395 - val_nmse: 0.3589\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1616 - nmse: 0.3942 - val_loss: 0.1350 - val_nmse: 0.3471\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1551 - nmse: 0.3709 - val_loss: 0.1265 - val_nmse: 0.3250\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1483 - nmse: 0.3706 - val_loss: 0.1240 - val_nmse: 0.3182\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1467 - nmse: 0.3501 - val_loss: 0.1226 - val_nmse: 0.3146\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1430 - nmse: 0.3668 - val_loss: 0.1237 - val_nmse: 0.3181\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.1429 - nmse: 0.3504 - val_loss: 0.1235 - val_nmse: 0.3174\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1389 - nmse: 0.3420 - val_loss: 0.1161 - val_nmse: 0.2978\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1338 - nmse: 0.3292 - val_loss: 0.1137 - val_nmse: 0.2916\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1298 - nmse: 0.3209 - val_loss: 0.1111 - val_nmse: 0.2847\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1271 - nmse: 0.3150 - val_loss: 0.1114 - val_nmse: 0.2857\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1234 - nmse: 0.3191 - val_loss: 0.1109 - val_nmse: 0.2841\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.1254 - nmse: 0.3193 - val_loss: 0.1131 - val_nmse: 0.2900\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 29s 6s/step - loss: 0.1230 - nmse: 0.3167 - val_loss: 0.1110 - val_nmse: 0.2844\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.1181 - nmse: 0.2942 - val_loss: 0.1106 - val_nmse: 0.2834\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1159 - nmse: 0.2897 - val_loss: 0.1100 - val_nmse: 0.2815\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.1122 - nmse: 0.2716 - val_loss: 0.1079 - val_nmse: 0.2761\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1084 - nmse: 0.2754 - val_loss: 0.1109 - val_nmse: 0.2840\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1075 - nmse: 0.2672 - val_loss: 0.1111 - val_nmse: 0.2845\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1031 - nmse: 0.2526 - val_loss: 0.1099 - val_nmse: 0.2811\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1012 - nmse: 0.2534 - val_loss: 0.1182 - val_nmse: 0.3031\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1046 - nmse: 0.2581 - val_loss: 0.1237 - val_nmse: 0.3172\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0989 - nmse: 0.2440 - val_loss: 0.1138 - val_nmse: 0.2916\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0938 - nmse: 0.2342 - val_loss: 0.1117 - val_nmse: 0.2860\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0905 - nmse: 0.2227 - val_loss: 0.1168 - val_nmse: 0.2992\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0846 - nmse: 0.2065 - val_loss: 0.1185 - val_nmse: 0.3033\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0807 - nmse: 0.2055 - val_loss: 0.1197 - val_nmse: 0.3066\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0761 - nmse: 0.1919 - val_loss: 0.1234 - val_nmse: 0.3156\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0751 - nmse: 0.1863 - val_loss: 0.1185 - val_nmse: 0.3032\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0686 - nmse: 0.1658 - val_loss: 0.1192 - val_nmse: 0.3045\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0651 - nmse: 0.1593 - val_loss: 0.1185 - val_nmse: 0.3030\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 23s 5s/step - loss: 0.0611 - nmse: 0.1533 - val_loss: 0.1219 - val_nmse: 0.3113\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0558 - nmse: 0.1367 - val_loss: 0.1252 - val_nmse: 0.3200\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0534 - nmse: 0.1307 - val_loss: 0.1211 - val_nmse: 0.3094\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0497 - nmse: 0.1243 - val_loss: 0.1245 - val_nmse: 0.3179\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0461 - nmse: 0.1150 - val_loss: 0.1309 - val_nmse: 0.3344\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0441 - nmse: 0.1097 - val_loss: 0.1363 - val_nmse: 0.3487\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0406 - nmse: 0.1006 - val_loss: 0.1267 - val_nmse: 0.3237\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0362 - nmse: 0.0899 - val_loss: 0.1268 - val_nmse: 0.3237\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0340 - nmse: 0.0845 - val_loss: 0.1298 - val_nmse: 0.3315\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0319 - nmse: 0.0789 - val_loss: 0.1267 - val_nmse: 0.3237\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0302 - nmse: 0.0755 - val_loss: 0.1269 - val_nmse: 0.3239\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0287 - nmse: 0.0712 - val_loss: 0.1294 - val_nmse: 0.3307\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0277 - nmse: 0.0687 - val_loss: 0.1280 - val_nmse: 0.3271\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0269 - nmse: 0.0663 - val_loss: 0.1256 - val_nmse: 0.3206\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 27s 5s/step - loss: 0.0251 - nmse: 0.0625 - val_loss: 0.1301 - val_nmse: 0.3323\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0237 - nmse: 0.0583 - val_loss: 0.1277 - val_nmse: 0.3261\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 33s 6s/step - loss: 0.0226 - nmse: 0.0565 - val_loss: 0.1263 - val_nmse: 0.3226\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 28s 5s/step - loss: 0.0217 - nmse: 0.0536 - val_loss: 0.1362 - val_nmse: 0.3482\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 28s 6s/step - loss: 0.0224 - nmse: 0.0561 - val_loss: 0.1352 - val_nmse: 0.3454\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0207 - nmse: 0.0520 - val_loss: 0.1299 - val_nmse: 0.3319\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0207 - nmse: 0.0511 - val_loss: 0.1284 - val_nmse: 0.3279\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0194 - nmse: 0.0486 - val_loss: 0.1314 - val_nmse: 0.3357\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0186 - nmse: 0.0458 - val_loss: 0.1284 - val_nmse: 0.3279\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0176 - nmse: 0.0440 - val_loss: 0.1291 - val_nmse: 0.3299\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0168 - nmse: 0.0416 - val_loss: 0.1285 - val_nmse: 0.3282\n",
      "Epoch 71/300\n",
      "3/5 [=================>............] - ETA: 10s - loss: 0.0162 - nmse: 0.0402"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#history = model.fit(X, Y, epochs=max_epoch, batch_size=batchsize, callbacks=[lr_scheduler], validation_split=validation_split)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      5\u001b[0m total_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myredv2\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myredv2\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myredv2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myredv2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myredv2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myredv2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myredv2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myredv2\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myredv2\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\myredv2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#history = model.fit(X, Y, epochs=max_epoch, batch_size=batchsize, callbacks=[lr_scheduler], validation_split=validation_split)\n",
    "history = model.fit(X, Y, epochs=max_epoch, batch_size=batchsize, validation_split=validation_split)\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "min_time = total_time / 60\n",
    "print(f'Tiempo total de entrenamiento: {min_time:.2f} minutos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################<br>\n",
    "#########################################################################################################<br>\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar el NMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['nmse'], label='NMSE (entrenamiento)')\n",
    "plt.plot(history.history['val_nmse'], label='NMSE (validacion)')\n",
    "plt.xlabel('Epoca')\n",
    "plt.ylabel('NMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GUARDAR UN MODELO ESPECÍFICO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio en donde se almacenara el modelo\n",
    "save_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_python/modelos_generados'\n",
    "os.makedirs(save_dir, exist_ok=True)  # Crear el directorio si no existe\n",
    "\n",
    "# Nombre del archivo del modelo\n",
    "model_name = 'unet_model_vscd_1_HEMU_v2.keras'\n",
    "\n",
    "# Ruta completa del archivo\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARGAR UN MODELO ESPECÍFICO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_cargado = tf.keras.models.load_model('D:/TT/Memoria/waveletycnn/codigo_python/modelos_generados/unet_model_7.keras',\n",
    "                                           custom_objects={'nmse': nmse})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARGAR COEFICIENTES (MATRIZ COMPLEJA) DE LA SEÑALES PAM ORIGINALES T OBTENER CANTIDAD DE MATRICES COMPLEJAS ENCONTRADAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_matrix_complex_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/inputs_coeficientes' # coeficientes de senal PAM original (sin ruido) en formato .mat\n",
    "output_matrix_complex_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/inputs_coeficientes_npy' # coeficientes de senal PAM original (sin ruido) en formato .npy\n",
    "os.makedirs(output_matrix_complex_pam_dir, exist_ok=True) # crear directorio \"output_matrix_complex_pam_dir\" si no existe\n",
    "\n",
    "# Se leen la cantidad de coeficientes o matrices complejas de senales PAM encontradas en el directorio \"input_matrix_complex_pam_dir\"\n",
    "total_matrix_complex_pam = sum(1 for filename in os.listdir(input_matrix_complex_pam_dir) if filename.endswith('.mat')) + 1\n",
    "print(\"Total de matrices complejas PAM encontradas -> \", total_matrix_complex_pam - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORMAR A FORMATO .npy LAS MATRICES COMPLEJAS ASOCIADAS A LA SEÑAL ORIGINAL PAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para convertir una matriz compleja de .mat a .npy\n",
    "def convert_mat_to_npy_original_signal(input_dir, output_dir, prefix):\n",
    "    for i in range(1, total_matrix_complex_pam):\n",
    "        mat_file = os.path.join(input_dir, f'{prefix}_{i}.mat')\n",
    "        npy_file = os.path.join(output_dir, f'{prefix}_npy_{i}.npy')\n",
    "        \n",
    "        # Cargar el archivo .mat\n",
    "        mat_data = loadmat(mat_file)\n",
    "        \n",
    "        # Extraer la matriz compleja\n",
    "        matrix_key = [key for key in mat_data.keys() if not key.startswith('__')][0]\n",
    "        matrix = mat_data[matrix_key]\n",
    "        \n",
    "        # Guardar la matriz en formato .npy\n",
    "        np.save(npy_file, matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las matrices comlejas de senales PAM originales de formato .mat a .npy\n",
    "convert_mat_to_npy_original_signal(input_matrix_complex_pam_dir, output_matrix_complex_pam_dir, 'matrix_complex_pam_to_predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREDECIR COEFICIENTES DE UNA SEÑAL DE VSC A PARTIR DE COEFICIENTES DE UNA SEÑAL PAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para predecir con el modelo entrenado\n",
    "def predecir_coefs(modelo_cargado, input_data):\n",
    "    coefs_predicted = modelo_cargado.predict(input_data)\n",
    "    return coefs_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listar todos los archivos en el directorio\n",
    "archivos_npy_dir = os.listdir(output_matrix_complex_pam_dir)\n",
    "# Filtrar solo los archivos .npy\n",
    "archivos_npy = [f for f in archivos_npy_dir if f.endswith('.npy')]\n",
    "\n",
    "# Cargar una matriz de entrada para hacer una prediccion \n",
    "# Leer el primer archivo .npy\n",
    "nombre_archivo_pam_npy = archivos_npy[0]\n",
    "archivo_pam_npy_dir = os.path.join(output_matrix_complex_pam_dir, nombre_archivo_pam_npy) # ELEGIR ARCHIVOS NPY A LEER (0, 1, 2, 3, 4, ...)\n",
    "\n",
    "#######################\n",
    "# ENTRADA PARA LA RED:\n",
    "######################\n",
    "input_matrix_pam = np.load(archivo_pam_npy_dir)\n",
    "print(\"Archivo cargado:\", archivo_pam_npy_dir)\n",
    "print(\"formato matrix complex input: \",input_matrix_pam.shape)\n",
    "\n",
    "tensor_input_matrix_pam = np.stack((input_matrix_pam.real, input_matrix_pam.imag), axis=-1)\n",
    "print(\"formato matrix complex input como tensor: \",tensor_input_matrix_pam.shape)\n",
    "\n",
    "# Expandir dimensiones para que coincidan con la forma esperada por el modelo\n",
    "tensor_input_matrix_pam = np.expand_dims(tensor_input_matrix_pam, axis=0)\n",
    "print(\"Formato matrix complex input con dimensión adicional:\", tensor_input_matrix_pam.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REALIZAR PREDICCIÓN (OBTENCIÓN DE COEFICIENTES DE SEÑAL VSC ESTIMADA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Realizar la predicción\n",
    "predicted_output = predecir_coefs(modelo_cargado, tensor_input_matrix_pam)\n",
    "\n",
    "# Mostrar la predicción\n",
    "print(\"Prediccion de la primera muestra de entrada:\")\n",
    "print(predicted_output)\n",
    "print(\"Formato de los coeficientes de la senal VSC estimada: \", predicted_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORMAR LA SALIDA ESTIMADA A UN FORMATO (36, 1024) Y LUEGO DE .npy a .mat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar la matriz tensor VSC a una matriz compleja de formato .mat\n",
    "# El tensor tiene la forma (1, 36, 1024, 2) y necesitamos transformarlo a (36, 1024) a matriz compleja\n",
    "complex_matrix_vsc = predicted_output[0, :, :, 0] + 1j * predicted_output[0, :, :, 1]\n",
    "print(\"Formato nuevo:\",complex_matrix_vsc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especificar la ruta completa del archivo, incluyendo el nombre y la extensión .mat\n",
    "ruta_archivo = \"D:\\TT\\Memoria\\waveletycnn\\codigo_matlab\\codigo_fuente\\coefs_vsc_predicted\\coefs_vsc_predicted.mat\"\n",
    "\n",
    "# Guardar la matriz compleja en el archivo especificado\n",
    "scipy.io.savemat(ruta_archivo, {'complex_matrix_vsc': complex_matrix_vsc})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORMACIÓN DE COEFICIENTES DE LA SENAL VSC ESTIMADA DE FORMATO .mat a .npy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GUARDADO DE LA MATRIZ COMPLEJA DE LA VSC ESTIMADA EN UNA CARPETA EN EL DIRECTORIO DE MATLAB EN FORMATO .mat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio donde se guardara la matriz compleja de la VSC estimada en formato .mat\n",
    "mat_dir = 'D:/TT/Memoria/waveletycnn/codigo_matlab/codigo_fuente/coefs_vsc_predicted'\n",
    "os.makedirs(mat_dir, exist_ok=True) # crear directorio \"mat_dir\" si no existe\n",
    "\n",
    "# Extraer el número como cadena\n",
    "numero_como_cadena = nombre_archivo_pam_npy.split('_')[-1].split('.')[0]\n",
    "\n",
    "# Nombre que tendra el archivo de la matriz compleja d la VSC estimada .mat. Se concatena el numero del archivo estimado\n",
    "mat_filename = f'matrix_complex_vsc_predicted_{numero_como_cadena}.mat'\n",
    "print(mat_filename)\n",
    "\n",
    "# Ruta completa del archivo .mat\n",
    "mat_path = os.path.join(mat_dir, mat_filename)\n",
    "\n",
    "\n",
    "try:\n",
    "    data = scipy.io.loadmat(mat_path)\n",
    "    print(\"El archivo es un archivo .mat válido.\")\n",
    "    print(data.keys())\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el archivo .mat: {e}\")\n",
    "\n",
    "\n",
    "# Guardar la matriz compleja en un archivo .mat {nombre archivo: contenido archivo}\n",
    "scipy.io.savemat(mat_path, {mat_filename: complex_matrix_vsc})\n",
    "\n",
    "print(f\"Archivo guardado en: {mat_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
