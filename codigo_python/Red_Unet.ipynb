{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Librerias para trabajar con la red neuronal y procesamiento de datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # type: ignore\n",
    "import scipy.io\n",
    "from scipy.io import loadmat # type: ignore\n",
    "import tensorflow as tf # Para red neuronal profunda\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time # Para tomar el tiempo de entrenamiento de la red\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CONVERTIR MATRICES DE: .mat  --> .npy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Directorios de entrada y salida: ***SUJETOS SANOS Y PACIENTES TEC***\n",
    "\n",
    "**(1) sujetos sanos:** 1_HEMU - 2_DAOC - 3_DASI - 4_DABA - 5_HEFU - 6_JOBO - 7_ROMI - 8_FEGA - 9_GAGO - 10_MIMO - 11_JULE - 12_NIGA - 13_BYLA - 14_ARVA - 15_CLSE - 16_PAAR - 17_VATO - 18_FEBE - 19_VINA - 20_CLHE - 21_MAIN - 22_ALSA - 23_MIRA - 24_LACA - 25_GOAC - 26_ANGL - 27_HC036101\n",
    "___________________________________________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "**(2) pacientes tec:** 1_DENI1005 - 2_KNOW1001 - 3_ALI0 - 4_BUTL - 5_HAGG - 6_HASTI007 - 7_BOAM - 8_DANE0005 - 9_GREG - 10_AITK - 11_RANS0000 - 12_JONES004 - 13_PERR - 14_SLAC - 15_HEPPL010 - 16_RICHS010 - 17_KENT0007 - 18_STAN1002 - 19_MCDON022 - 20_PULL - 21_MORR1002 - 22_PARK - 23_HIGH - 24_NOBL - 25_COWL - 26_KHAN - 27_NOLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS/1_HEMU/PAMnoises_matrixcomplex_mat\n",
      "D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS/1_HEMU/VSCdnoises_matrixcomplex_mat\n",
      "D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS/1_HEMU/VSCinoises_matrixcomplex_mat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Directorios de las matrices complejas (coeficientes) de las senales PAM ,VSCd y VSCi de suejtos sanos o pacientes con tec. Se debe modificar estos directorios para ir\n",
    "# generando los respectivos modelos de cada individuo.\n",
    "\n",
    "# DIRECTORIOS: SUJETO SANO\n",
    "\n",
    "# SUJETO SANO O PACIENTE TEC POR ANALIZAR\n",
    "persona = 'SANOS/1_HEMU'\n",
    "# Sector de la VSC por analizar (derecho o izquierdo):\n",
    "sector = 'derecho'\n",
    " # INPUT PARA LA RED\n",
    "# INPUT PAM\n",
    "input_pam_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/PAMnoises_matrixcomplex_mat'\n",
    "# INPUT VSCd\n",
    "input_vscd_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/VSCdnoises_matrixcomplex_mat'\n",
    "# INPUT VSCI\n",
    "input_vsci_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/VSCinoises_matrixcomplex_mat'\n",
    "\n",
    "# OUTPUT O SALIDAS ESPERADAS PARA LA RED\n",
    "# OUTPUT PAM\n",
    "output_pam_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/PAMnoises_matrixcomplex_npy'\n",
    "# OUTPUT PAM\n",
    "output_vscd_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/VSCdnoises_matrixcomplex_npy'\n",
    "# OUTPUT PAM\n",
    "output_vsci_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/VSCinoises_matrixcomplex_npy'\n",
    "\n",
    "\n",
    "#######################################################################################################################################################\n",
    "#######################################################################################################################################################\n",
    "#######################################################################################################################################################\n",
    "\n",
    "\n",
    "# DIRECTORIOS: PACIENTE TEC\n",
    "#paciente_tec = '/1_DENI1005'\n",
    "\n",
    "\n",
    " # INPUT PARA LA RED\n",
    "# INPUT PAM\n",
    "#input_pam_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/TEC' + persona + '/PAMnoises_matrixcomplex_mat'\n",
    "# INPUT VSCd\n",
    "#input_vscd_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/TEC' + persona + '/VSCdnoises_matrixcomplex_mat'\n",
    "# INPUT VSCI\n",
    "#input_vsci_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/TEC' + persona + '/VSCinoises_matrixcomplex_mat'\n",
    "\n",
    "# OUTPUT O SALIDAS ESPERADAS PARA LA RED\n",
    "# OUTPUT PAM\n",
    "#output_pam_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/TEC' + persona + '/PAMnoises_matrixcomplex_npy'\n",
    "# OUTPUT PAM\n",
    "#output_vscd_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/TEC' + persona + '/VSCdnoises_matrixcomplex_npy'\n",
    "# OUTPUT PAM\n",
    "#output_vsci_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/TEC' + persona + '/VSCinoises_matrixcomplex_npy'\n",
    "\n",
    "\n",
    "print(input_pam_dir)\n",
    "print(input_vscd_dir)\n",
    "print(input_vsci_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear los directorios de salida si no existen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_pam_dir, exist_ok=True) # DIRECTORIO PARA GUARDAR MATRICES COMPLEJAS DE PAM EN FORMATO .npy\n",
    "os.makedirs(output_vscd_dir, exist_ok=True) # DIRECTORIO PARA GUARDAR MATRICES COMPLEJAS DE VSCd EN FORMATO .npy\n",
    "os.makedirs(output_vsci_dir, exist_ok=True) # DIRECTORIO PARA GUARDAR MATRICES COMPLEJAS DE VSCi EN FORMATO .npy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para convertir archivos .mat a .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de archivos a analizar ->  50\n"
     ]
    }
   ],
   "source": [
    "total_files=sum(1 for filename in os.listdir(input_pam_dir) if filename.endswith('.mat')) + 1\n",
    "print(\"Total de archivos a analizar -> \",total_files-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mat_to_npy(input_dir, output_dir, prefix):\n",
    "    for i in range(1, total_files):\n",
    "        mat_file = os.path.join(input_dir, f'{prefix}_noise_{i}.mat')\n",
    "        npy_file = os.path.join(output_dir, f'{prefix}_noise_{i}.npy')\n",
    "        \n",
    "        # Cargar el archivo .mat\n",
    "        mat_data = loadmat(mat_file)\n",
    "        \n",
    "        # Extraer la matriz compleja\n",
    "        matrix_key = [key for key in mat_data.keys() if not key.startswith('__')][0]\n",
    "        matrix = mat_data[matrix_key]\n",
    "        \n",
    "        # Guardar la matriz en formato .npy\n",
    "        np.save(npy_file, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertir archivos .mat a .npy para PAM y VSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_mat_to_npy(input_pam_dir, output_pam_dir, 'matrix_complex_pam')\n",
    "convert_mat_to_npy(input_vscd_dir, output_vscd_dir, 'matrix_complex_vscd')\n",
    "convert_mat_to_npy(input_vsci_dir, output_vsci_dir, 'matrix_complex_vsci')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversion a tensor tridimensional** (Estructura adecuada para entrenar la red U-net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios salida para matrices con estructura tensor tridimensional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pam_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/PAMnoises_matrixcomplex_npy'\n",
    "input_vscd_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/VSCdnoises_matrixcomplex_npy'\n",
    "input_vsci_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/VSCinoises_matrixcomplex_npy'\n",
    "\n",
    "output_pam_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/PAMnoises_matrixcomplex_npy_tensor3d'\n",
    "output_vscd_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/VSCdnoises_matrixcomplex_npy_tensor3d'\n",
    "output_vsci_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/VSCinoises_matrixcomplex_npy_tensor3d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear directorios de salida si no existen (matrices complejas en forma de tensor tridimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(output_pam_dir, exist_ok=True)\n",
    "os.makedirs(output_vscd_dir, exist_ok=True)\n",
    "os.makedirs(output_vsci_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####################################################\n",
    "PREPROCESAMIENTO ANTES DE NORMALIZACIÓN DE MATRICES\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CÁLCULO DE LA MEDIA - PAM & VSC (la media se calcula teniendo en cuenta todas las matrices)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acumuladores para calcular la media de cada matriz (real e imaginaria) y la desviacion estandar\n",
    "\n",
    "#==========================\n",
    "#=== PAM SIGNAl ===========\n",
    "#==========================\n",
    "#===\n",
    "# Para media\n",
    "#===\n",
    "sumatoria_real_pam = 0\n",
    "media_real_pam = 0\n",
    "\n",
    "sumatoria_imag_pam = 0\n",
    "media_imag_pam = 0\n",
    "#===\n",
    "# Para la desviacion estandar\n",
    "#===\n",
    "sumatoria_real_cuadrada_pam = 0\n",
    "sumatoria_imag_cuadrada_pam = 0\n",
    "\n",
    "desv_real_pam = 0\n",
    "desv_imag_pam = 0\n",
    "\n",
    "\n",
    "#==========================\n",
    "#=== VSC SIGNAl ===========\n",
    "#==========================\n",
    "#===\n",
    "# Para media\n",
    "#===\n",
    "sumatoria_real_vsc = 0\n",
    "media_real_vsc = 0\n",
    "\n",
    "sumatoria_imag_vsc = 0\n",
    "media_imag_vsc = 0\n",
    "#===\n",
    "# Para la desviacion estandar\n",
    "#===\n",
    "sumatoria_real_cuadrada_vsc = 0\n",
    "sumatoria_imag_cuadrada_vsc = 0\n",
    "\n",
    "desv_real_vsc = 0\n",
    "desv_imag_vsc = 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCIONES PARA EL CÁLCULO DE LA MEDIA Y DESVIACIÓN ESTÁNDAR PARA LAS SEÑALES [[  PAM  ]]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte real de una matriz compleja PAM)\n",
    "def sumatoria_acumulada_real_pam(matriz):\n",
    "    global sumatoria_real_pam\n",
    "    sumatoria_real_pam = sumatoria_real_pam + np.sum(matriz)\n",
    "    #print(sumatoria_real_pam)\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_cuadrada_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices PAM.\n",
    "def sumatoria_acumulada_real_cuadrada_pam(matriz):\n",
    "    global sumatoria_real_cuadrada_pam, media_real_pam\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_real_cuadrada_pam = sumatoria_real_cuadrada_pam + (elemento - media_real_pam)**2\n",
    "\n",
    "\n",
    "#=====================================================================================================================================================\n",
    "#=====================================================================================================================================================\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte imaginaria de una matriz compleja PAM)\n",
    "def sumatoria_acumulada_imag_pam(matriz):\n",
    "    global sumatoria_imag_pam\n",
    "    sumatoria_imag_pam = sumatoria_imag_pam + np.sum(matriz)\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_cuadrada_pam(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices PAM.\n",
    "def sumatoria_acumulada_imag_cuadrada_pam(matriz):\n",
    "    global sumatoria_imag_cuadrada_pam, media_imag_pam\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_imag_cuadrada_pam = sumatoria_imag_cuadrada_pam + (elemento - media_imag_pam)**2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FUNCIONES PARA EL CÁLCULO DE LA MEDIA Y DESVIACIÓN ESTÁNDAR PARA LAS SEÑALES [[  VSC  ]]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte real de una matriz compleja VSC)\n",
    "def sumatoria_acumulada_real_vsc(matriz):\n",
    "    global sumatoria_real_vsc\n",
    "    sumatoria_real_vsc = sumatoria_real_vsc + np.sum(matriz)\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_real_cuadrada_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices VSC.\n",
    "def sumatoria_acumulada_real_cuadrada_vsc(matriz):\n",
    "    global sumatoria_real_cuadrada_vsc, media_real_vsc\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_real_cuadrada_vsc = sumatoria_real_cuadrada_vsc + (elemento - media_real_vsc)**2\n",
    "\n",
    "\n",
    "#=====================================================================================================================================================\n",
    "#=====================================================================================================================================================\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que suma todos los elementos de una matriz (parte imaginaria de una matriz compleja VSC)\n",
    "def sumatoria_acumulada_imag_vsc(matriz):\n",
    "    global sumatoria_imag_vsc\n",
    "    sumatoria_imag_vsc = sumatoria_imag_vsc + np.sum(matriz)\n",
    "\n",
    "\n",
    "#Entrada: matriz(array bidimensiional nxm), sumatoria_imag_cuadrada_vsc(int)\n",
    "#Salida: -\n",
    "#Descripcion: funcion que tiene como objetivo calcular el (x - u)^2 para su posterior uso en el calculo de la desviacion estandar. \n",
    "#             Con \"x\" cada elementos de la matriz y \"u\" la media de todas las matrices VSC.\n",
    "def sumatoria_acumulada_imag_cuadrada_vsc(matriz):\n",
    "    global sumatoria_imag_cuadrada_vsc, media_imag_vsc\n",
    "    for fila in matriz:\n",
    "        for elemento in fila:\n",
    "            sumatoria_imag_cuadrada_vsc = sumatoria_imag_cuadrada_vsc + (elemento - media_imag_vsc)**2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES & CÁLCULO DE LA MEDIA  MATRIZ PAM (Presion Arterial Media)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_pam_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        #========\n",
    "        # Normalizacion de los matrices\n",
    "        #========\n",
    "        # Sumar todos los datos de las matrices\n",
    "        sumatoria_acumulada_real_pam(matriz_compleja.real) # para matriz real\n",
    "        sumatoria_acumulada_imag_pam(matriz_compleja.imag) # para matriz imaginaria\n",
    "\n",
    "\n",
    "\n",
    "# Se calcula la media real de matrices correspondientes a pam signals: Se suman cada unos de los coeficientes de cada matriz real pam (archivos x filas x columnas)\n",
    "num_files_input_pam_dir = sum(1 for filename in os.listdir(input_pam_dir) if filename.endswith('.npy'))\n",
    "filas_matriz, columnas_matriz = matriz_compleja.shape\n",
    "coefs_totales =  num_files_input_pam_dir * filas_matriz * columnas_matriz # N\n",
    "media_real_pam = sumatoria_real_pam / coefs_totales # MEDIA REAL\n",
    "media_imag_pam = sumatoria_imag_pam / coefs_totales # MEDIA IMAGINARIA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES Y CÁLCULO DE LA DESVIACIÓN ESTÁNDAR || MATRIZ PAM (Presion Arterial Media)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_pam_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz real\n",
    "        sumatoria_acumulada_real_cuadrada_pam(matriz_compleja.real)\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz imaginaria\n",
    "        sumatoria_acumulada_imag_cuadrada_pam(matriz_compleja.imag)\n",
    "\n",
    "# Se calcula de desviacion estandar de las matrices reales e imaginarias\n",
    "desv_real_pam = np.square(sumatoria_real_cuadrada_pam/coefs_totales)\n",
    "desv_imag_pam = np.square(sumatoria_imag_cuadrada_pam/coefs_totales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#==============================================================================================================================\n",
    "#==============================================================================================================================\n",
    "#=============================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES & CÁLCULO DE LA MEDIA MATRIZ VSC (Velocidad Sanguínea Cerebral)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        #========\n",
    "        # Normalizacion de los matrices\n",
    "        #========\n",
    "        # Sumar todos los datos de las matrices\n",
    "        sumatoria_acumulada_real_vsc(matriz_compleja.real) # para matriz real\n",
    "        sumatoria_acumulada_imag_vsc(matriz_compleja.imag) # para matriz imaginaria\n",
    "\n",
    "\n",
    "\n",
    "# Se calcula la media real de matrices correspondientes a vsc signals: Se suman cada unos de los coeficientes de cada matriz real vsc (archivos x filas x columnas)\n",
    "num_files_input_vsc_dir = sum(1 for filename in os.listdir(input_vsc_dir) if filename.endswith('.npy'))\n",
    "media_real_vsc = sumatoria_real_vsc / coefs_totales # MEDIA REAL\n",
    "media_imag_vsc = sumatoria_imag_vsc / coefs_totales # MEDIA IMAGINARIA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECORRER MATRICES Y CÁLCULO DE LA DESVIACIÓN ESTÁNDAR || MATRIZ VSC (Velocidad Sanguínea Cerebral)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz real\n",
    "        sumatoria_acumulada_real_cuadrada_vsc(matriz_compleja.real)\n",
    "        # Calculo de sumatoria(x - u)^2 - matriz imaginaria\n",
    "        sumatoria_acumulada_imag_cuadrada_vsc(matriz_compleja.imag)\n",
    "\n",
    "# Se calcula de desviacion estandar de las matrices reales e imaginarias\n",
    "desv_real_vsc = np.square(sumatoria_real_cuadrada_vsc/coefs_totales)\n",
    "desv_imag_vsc = np.square(sumatoria_imag_cuadrada_vsc/coefs_totales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**APLICACIÓN DE NORMALIZACION A LAS MATRICES PAM Y VSC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############################################################\n",
    "**NORMALIZACION MIN-MAX**\n",
    "##############################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_real_pam = 1000000\n",
    "min_imag_pam = 1000000\n",
    "max_real_pam = -100\n",
    "max_imag_pam = -100\n",
    "\n",
    "min_real_vsc = 1000000\n",
    "min_imag_vsc = 1000000\n",
    "max_real_vsc = -100\n",
    "max_imag_vsc = -100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#PAM: encontrar min y max de matrices reales e imaginarias\n",
    "def encontrar_min_pam(matriz):\n",
    "    global min_real_pam, min_imag_pam\n",
    "    if np.min(matriz.real) < min_real_pam:\n",
    "        min_real_pam = np.min(matriz.real)\n",
    "\n",
    "    if np.min(matriz.imag) < min_imag_pam:\n",
    "        min_imag_pam = np.min(matriz.imag)\n",
    "\n",
    "\n",
    "def encontrar_max_pam(matriz):\n",
    "    global max_real_pam, max_imag_pam\n",
    "    if np.max(matriz.real) > max_real_pam:\n",
    "        max_real_pam = np.max(matriz.real)\n",
    "\n",
    "    if np.max(matriz.imag) > max_imag_pam:\n",
    "        max_imag_pam = np.max(matriz.imag)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "#################################################################################################\n",
    "\n",
    "\n",
    "#VSC: encontrar min y max de matrices reales e imaginarias\n",
    "\n",
    "def encontrar_min_vsc(matriz):\n",
    "    global min_real_vsc, min_imag_vsc\n",
    "    if np.min(matriz.real) < min_real_vsc:\n",
    "        min_real_vsc = np.min(matriz.real)\n",
    "\n",
    "    if np.min(matriz.imag) < min_imag_vsc:\n",
    "        min_imag_vsc = np.min(matriz.imag)\n",
    "\n",
    "\n",
    "def encontrar_max_vsc(matriz):\n",
    "    global max_real_vsc, max_imag_vsc\n",
    "    if np.max(matriz.real) > max_real_vsc:\n",
    "        max_real_vsc = np.max(matriz.real)\n",
    "\n",
    "    if np.max(matriz.imag) > max_imag_vsc:\n",
    "        max_imag_vsc = np.max(matriz.imag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TESTING MIN-MAX\n",
    "#PAM\n",
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Iterando sobre todas las matrices para encontrar el min y max\n",
    "        encontrar_min_pam(matriz_compleja)\n",
    "        encontrar_max_pam(matriz_compleja)\n",
    "\n",
    "#VSC\n",
    "for filename in os.listdir(input_vsc_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        # Se obtiene el archivo .npy en el directorio \"input_vsc_dir\"\n",
    "        input_path = os.path.join(input_vsc_dir, filename)\n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "\n",
    "        # Iterando sobre todas las matrices para encontrar el min y max\n",
    "        encontrar_min_vsc(matriz_compleja)\n",
    "        encontrar_max_vsc(matriz_compleja)\n",
    "        \n",
    "\n",
    "print(min_real_pam)\n",
    "print(min_imag_pam)\n",
    "print(max_real_pam)\n",
    "print(max_imag_pam)\n",
    "\n",
    "print(\"------------\")\n",
    "\n",
    "print(min_real_vsc)\n",
    "print(min_imag_vsc)\n",
    "print(max_real_vsc)\n",
    "print(max_imag_vsc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############################################################\n",
    "**NORMALIZACION Z-CORE**\n",
    "##############################################################\n",
    "z = (x - u) / desv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Entrada: matriz_compleja PAM (array bidimensional)\n",
    "#Salida: z_real (matriz real de pam normalizada), z_imag (matriz imag de pam normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz pam y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_pam(matriz_compleja):\n",
    "    global media_real_pam, media_imag_pam, desv_real_pam, desv_imag_pam\n",
    "    # Aplicacion de normalziacion z-core || z=(x - u)/desv\n",
    "    z_real = (matriz_compleja.real - media_real_pam) / desv_real_pam # normalizarcion parte real pam\n",
    "    z_imag = (matriz_compleja.imag - media_imag_pam) / desv_imag_pam # normalizacion parte imaginaria pam\n",
    "    return z_real, z_imag\n",
    "\n",
    "#Entrada: matriz_compleja PAM (array bidimensional)\n",
    "#Salida: z_real (matriz real de pam normalizada), z_imag (matriz imag de pam normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz pam y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_vsc(matriz_compleja):\n",
    "    global media_real_vsc, media_imag_vsc, desv_real_vsc, desv_imag_vsc\n",
    "    # Aplicacion de normalziacion z-core || z=(x - u)/desv\n",
    "    z_real = (matriz_compleja.real - media_real_vsc) / desv_real_vsc # normalizarcion parte real pam\n",
    "    z_imag = (matriz_compleja.imag - media_imag_vsc) / desv_imag_vsc # normalizacion parte imaginaria pam\n",
    "    return z_real, z_imag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NORMALIZACIÓN MEDIANTE MIN - MAX**<br>\n",
    "Ni = (Xi - Xmin) / (Xmax - Xmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#Entrada: matriz_compleja (array bidimensional de matriz PAM)\n",
    "#Salida: n_real (matriz real de pam normalizada), n_imag (matriz imag de pam normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz pam y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_minmax_pam(matriz_compleja):\n",
    "    global min_real_pam, max_real_pam, min_imag_pam, max_imag_pam\n",
    "    n_real = (matriz_compleja.real - min_real_pam) / (max_real_pam - min_real_pam)\n",
    "    n_imag = (matriz_compleja.imag - min_imag_pam) / (max_imag_pam - min_imag_pam)\n",
    "    return n_real, n_imag\n",
    "\n",
    "\n",
    "#Entrada: matriz_compleja (array bidimensional de matriz VSC)\n",
    "#Salida: n_real (matriz real de vsc normalizada), n_imag (matriz imag de vsc normalizada)\n",
    "#Descripcion: funcion encargada de normalizar una matriz vsc y retornar las matrices real e imaginarias normalizadas\n",
    "def normalizacion_minmax_vsc(matriz_compleja):\n",
    "    global min_real_vsc, max_real_vsc,  min_imag_vsc, max_imag_vsc\n",
    "    n_real = (matriz_compleja.real - min_real_vsc) / (max_real_vsc - min_real_vsc)\n",
    "    n_imag = (matriz_compleja.imag - min_imag_vsc) / (max_imag_vsc - min_imag_vsc)\n",
    "    return n_real, n_imag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAR MATRICES SEGÚN UNA NORMALIZACIÓN Y ORGANIZAR DATOS PARA LA RED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Entrada: matriz_compleja (array bidimensional)\n",
    "#Salida: datos_organizados (tensor de datos de la matriz pam)\n",
    "#Descripcion: funcion encargada de normalizar cada matriz pam y definir el input para la red u-net\n",
    "def procesar_matriz_compleja_pam(matriz_compleja):\n",
    "    \n",
    "    # Aplicacion de normalziacion Z-CORE || z = (x - u) / desv\n",
    "    #norm_real, norm_imag = normalizacion_pam(matriz_compleja)\n",
    "\n",
    "    # Aplicacion de normalziacion MIN-MAX || Ni = (Xi - Xmin) / (Xmax - Xmin)\n",
    "    #norm_real, norm_imag = normalizacion_minmax_pam(matriz_compleja)\n",
    "\n",
    "    # Crear input adecuado\n",
    "    #datos_organizados = np.stack((norm_real, norm_imag), axis=-1)\n",
    "    datos_organizados = np.stack((matriz_compleja.real, matriz_compleja.imag), axis=-1)\n",
    "    return datos_organizados\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Entrada: matriz_compleja (array bidimensional)\n",
    "#Salida: datos_organizados (tensor de datos de la matriz vsc)\n",
    "#Descripcion: funcion encargada de normalizar cada matriz vsc y definir el input para la red u-net\n",
    "def procesar_matriz_compleja_vsc(matriz_compleja):\n",
    "    \n",
    "    # Aplicacion de normalziacion Z-CORE || z=(x - u)/desv\n",
    "    #norm_real, norm_imag = normalizacion_vsc(matriz_compleja)\n",
    "\n",
    "    # Aplicacion de normalziacion MIN-MAX || Ni = (Xi-Xmin)/(Xmax-Xmin)\n",
    "    #norm_real, norm_imag = normalizacion_minmax_vsc(matriz_compleja)\n",
    "    \n",
    "    # Crear input adecuado\n",
    "    #datos_organizados = np.stack((norm_real, norm_imag), axis=-1)\n",
    "    datos_organizados = np.stack((matriz_compleja.real, matriz_compleja.imag), axis=-1)\n",
    "    return datos_organizados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAR MATRICES COMPLEJAS EN LA CARPETA input_pam_dir y procesar matrices mediante una normalización**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(input_pam_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        input_path = os.path.join(input_pam_dir, filename)\n",
    "        output_path = os.path.join(output_pam_dir, filename)\n",
    "        \n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        # Procesar la matriz compleja segun una normalizacion\n",
    "        datos_organizados = procesar_matriz_compleja_pam(matriz_compleja)\n",
    "        \n",
    "        # Guardar los datos procesados\n",
    "        np.save(output_path, datos_organizados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAR MATRICES COMPLEJAS EN LA CARPETA input_vscd_dir**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesamiento completado.\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(input_vscd_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        input_path = os.path.join(input_vscd_dir, filename)\n",
    "        output_path = os.path.join(output_vscd_dir, filename)\n",
    "        \n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        # Procesar la matriz compleja segun una normalizacion\n",
    "        datos_organizados = procesar_matriz_compleja_vsc(matriz_compleja)\n",
    "        \n",
    "        # Guardar los datos procesados\n",
    "        np.save(output_path, datos_organizados)\n",
    "        \n",
    "print(\"Procesamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROCESAR MATRICES COMPLEJAS EN LA CARPETA input_vsci_dir**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesamiento completado.\n"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(input_vsci_dir):\n",
    "    if filename.endswith('.npy'):\n",
    "        input_path = os.path.join(input_vsci_dir, filename)\n",
    "        output_path = os.path.join(output_vsci_dir, filename)\n",
    "        \n",
    "        # Cargar la matriz compleja\n",
    "        matriz_compleja = np.load(input_path)\n",
    "        \n",
    "        # Procesar la matriz compleja segun una normalizacion\n",
    "        datos_organizados = procesar_matriz_compleja_vsc(matriz_compleja)\n",
    "        \n",
    "        # Guardar los datos procesados\n",
    "        np.save(output_path, datos_organizados)\n",
    "        \n",
    "print(\"Procesamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verificacion de \"shape\" - matrices pam y vsc**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de salida a verificar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pam_dir_check = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/PAMnoises_matrixcomplex_npy_tensor3d'\n",
    "output_vscd_dir_check = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/VSCdnoises_matrixcomplex_npy_tensor3d'\n",
    "output_vsci_dir_check = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/VSCinoises_matrixcomplex_npy_tensor3d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para verificar la forma de una matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_shape(directorio, nombre_archivo):\n",
    "    path = os.path.join(directorio, nombre_archivo)\n",
    "    matriz = np.load(path)\n",
    "    return matriz.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar la forma de un archivo de ejemplo en output_pam_dir_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de matrix_complex_pam_noise_1.npy en D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS/1_HEMU/PAMnoises_matrixcomplex_npy_tensor3d: (36, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "ejemplo_pam = os.listdir(output_pam_dir_check)[0]  # Obtener el primer archivo de la carpeta\n",
    "shape_pam = verificar_shape(output_pam_dir_check, ejemplo_pam)\n",
    "print(f\"Shape de {ejemplo_pam} en {output_pam_dir_check}: {shape_pam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar la forma de un archivo de ejemplo en output_vscd_dir_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de matrix_complex_vscd_noise_1.npy en D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS/1_HEMU/VSCdnoises_matrixcomplex_npy_tensor3d: (36, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "ejemplo_vscd = os.listdir(output_vscd_dir_check)[0]  # Obtener el primer archivo de la carpeta\n",
    "shape_vscd = verificar_shape(output_vscd_dir_check, ejemplo_vscd)\n",
    "print(f\"Shape de {ejemplo_vscd} en {output_vscd_dir_check}: {shape_vscd}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar la forma de un archivo de ejemplo en output_vsci_dir_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de matrix_complex_vsci_noise_1.npy en D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/SANOS/1_HEMU/VSCinoises_matrixcomplex_npy_tensor3d: (36, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "ejemplo_vsci = os.listdir(output_vsci_dir_check)[0]  # Obtener el primer archivo de la carpeta\n",
    "shape_vsci = verificar_shape(output_vsci_dir_check, ejemplo_vsci)\n",
    "print(f\"Shape de {ejemplo_vsci} en {output_vsci_dir_check}: {shape_vsci}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                **|||Red Neuronal Profunda: U-net|||**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directorios de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENAL PAM\n",
    "input_pam_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/PAMnoises_matrixcomplex_npy_tensor3d'\n",
    "# VSC LADO DERECHO\n",
    "output_vscd_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/VSCdnoises_matrixcomplex_npy_tensor3d'\n",
    "# VSC LADO IZQUIERDO\n",
    "output_vsci_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona + '/VSCinoises_matrixcomplex_npy_tensor3d'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion para cargar los archivos .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_files(input_dir):\n",
    "    files = sorted([os.path.join(input_dir, f) for f in os.listdir(input_dir) if f.endswith('.npy')])\n",
    "     # verificar orden con que entrar los archivos en X e Y\n",
    "    file_names = [os.path.basename(f) for f in files]\n",
    "    print(f\"Archivos: {file_names}\\n\")\n",
    "    data = [np.load(f) for f in files]\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA DE DATOS DE ENTRADAS Y SALIDAS PARA LA RED (X: INPUTS; Y: OUTPUTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos: ['matrix_complex_pam_noise_1.npy', 'matrix_complex_pam_noise_10.npy', 'matrix_complex_pam_noise_11.npy', 'matrix_complex_pam_noise_12.npy', 'matrix_complex_pam_noise_13.npy', 'matrix_complex_pam_noise_14.npy', 'matrix_complex_pam_noise_15.npy', 'matrix_complex_pam_noise_16.npy', 'matrix_complex_pam_noise_17.npy', 'matrix_complex_pam_noise_18.npy', 'matrix_complex_pam_noise_19.npy', 'matrix_complex_pam_noise_2.npy', 'matrix_complex_pam_noise_20.npy', 'matrix_complex_pam_noise_21.npy', 'matrix_complex_pam_noise_22.npy', 'matrix_complex_pam_noise_23.npy', 'matrix_complex_pam_noise_24.npy', 'matrix_complex_pam_noise_25.npy', 'matrix_complex_pam_noise_26.npy', 'matrix_complex_pam_noise_27.npy', 'matrix_complex_pam_noise_28.npy', 'matrix_complex_pam_noise_29.npy', 'matrix_complex_pam_noise_3.npy', 'matrix_complex_pam_noise_30.npy', 'matrix_complex_pam_noise_31.npy', 'matrix_complex_pam_noise_32.npy', 'matrix_complex_pam_noise_33.npy', 'matrix_complex_pam_noise_34.npy', 'matrix_complex_pam_noise_35.npy', 'matrix_complex_pam_noise_36.npy', 'matrix_complex_pam_noise_37.npy', 'matrix_complex_pam_noise_38.npy', 'matrix_complex_pam_noise_39.npy', 'matrix_complex_pam_noise_4.npy', 'matrix_complex_pam_noise_40.npy', 'matrix_complex_pam_noise_41.npy', 'matrix_complex_pam_noise_42.npy', 'matrix_complex_pam_noise_43.npy', 'matrix_complex_pam_noise_44.npy', 'matrix_complex_pam_noise_45.npy', 'matrix_complex_pam_noise_46.npy', 'matrix_complex_pam_noise_47.npy', 'matrix_complex_pam_noise_48.npy', 'matrix_complex_pam_noise_49.npy', 'matrix_complex_pam_noise_5.npy', 'matrix_complex_pam_noise_50.npy', 'matrix_complex_pam_noise_6.npy', 'matrix_complex_pam_noise_7.npy', 'matrix_complex_pam_noise_8.npy', 'matrix_complex_pam_noise_9.npy']\n",
      "\n",
      "Archivos: ['matrix_complex_vscd_noise_1.npy', 'matrix_complex_vscd_noise_10.npy', 'matrix_complex_vscd_noise_11.npy', 'matrix_complex_vscd_noise_12.npy', 'matrix_complex_vscd_noise_13.npy', 'matrix_complex_vscd_noise_14.npy', 'matrix_complex_vscd_noise_15.npy', 'matrix_complex_vscd_noise_16.npy', 'matrix_complex_vscd_noise_17.npy', 'matrix_complex_vscd_noise_18.npy', 'matrix_complex_vscd_noise_19.npy', 'matrix_complex_vscd_noise_2.npy', 'matrix_complex_vscd_noise_20.npy', 'matrix_complex_vscd_noise_21.npy', 'matrix_complex_vscd_noise_22.npy', 'matrix_complex_vscd_noise_23.npy', 'matrix_complex_vscd_noise_24.npy', 'matrix_complex_vscd_noise_25.npy', 'matrix_complex_vscd_noise_26.npy', 'matrix_complex_vscd_noise_27.npy', 'matrix_complex_vscd_noise_28.npy', 'matrix_complex_vscd_noise_29.npy', 'matrix_complex_vscd_noise_3.npy', 'matrix_complex_vscd_noise_30.npy', 'matrix_complex_vscd_noise_31.npy', 'matrix_complex_vscd_noise_32.npy', 'matrix_complex_vscd_noise_33.npy', 'matrix_complex_vscd_noise_34.npy', 'matrix_complex_vscd_noise_35.npy', 'matrix_complex_vscd_noise_36.npy', 'matrix_complex_vscd_noise_37.npy', 'matrix_complex_vscd_noise_38.npy', 'matrix_complex_vscd_noise_39.npy', 'matrix_complex_vscd_noise_4.npy', 'matrix_complex_vscd_noise_40.npy', 'matrix_complex_vscd_noise_41.npy', 'matrix_complex_vscd_noise_42.npy', 'matrix_complex_vscd_noise_43.npy', 'matrix_complex_vscd_noise_44.npy', 'matrix_complex_vscd_noise_45.npy', 'matrix_complex_vscd_noise_46.npy', 'matrix_complex_vscd_noise_47.npy', 'matrix_complex_vscd_noise_48.npy', 'matrix_complex_vscd_noise_49.npy', 'matrix_complex_vscd_noise_5.npy', 'matrix_complex_vscd_noise_50.npy', 'matrix_complex_vscd_noise_6.npy', 'matrix_complex_vscd_noise_7.npy', 'matrix_complex_vscd_noise_8.npy', 'matrix_complex_vscd_noise_9.npy']\n",
      "\n",
      "Modelo para VSC: sector derecho del cerebro.\n",
      "\n",
      "Abreviacion de sector a estudiar: vscd\n"
     ]
    }
   ],
   "source": [
    "# Se identifica que sector del cerebro se desea analizar:\n",
    "lado = ''\n",
    "if sector == 'derecho':\n",
    "    X = load_npy_files(input_pam_dir) # inputs\n",
    "    Y = load_npy_files(output_vscd_dir) # outputs\n",
    "    lado = 'vscd'\n",
    "    print('Modelo para VSC: sector derecho del cerebro.\\n')\n",
    "else:\n",
    "    X = load_npy_files(input_pam_dir) # inputs\n",
    "    Y = load_npy_files(output_vsci_dir) # outputs\n",
    "    lado = 'vsci'\n",
    "    print('Modelo para VSC: sector izquierdo del cerebro.\\n')\n",
    "print('Abreviacion de sector a estudiar:', lado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar las formas de los datos cargados (# entradas, filas, columnas, canales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de los inputs (X): (50, 36, 1024, 2)\n",
      "Shape de los outputs (Y): (50, 36, 1024, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape de los inputs (X): {X.shape}\")\n",
    "print(f\"Shape de los outputs (Y): {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la U-Net con regularizacion L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def unet_model_with_l2(input_shape, l2_lambda):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Regularizer\n",
    "    l2_reg = tf.keras.regularizers.l2(l2_lambda)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(inputs)\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c1)\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(p1)\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c2)\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(p2)\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c3)\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3)\n",
    "    u4 = tf.keras.layers.concatenate([u4, c2])\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(u4)\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c4)\n",
    "    \n",
    "    u5 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4)\n",
    "    u5 = tf.keras.layers.concatenate([u5, c1])\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(u5)\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=l2_reg)(c5)\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(2, (1, 1), activation='linear')(c5)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model\n",
    "'''\n",
    "\n",
    "def unet_model(input_shape):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Regularizer\n",
    "    #l2_reg = tf.keras.regularizers.l2(l2_lambda)\n",
    "    \n",
    "    # Encoder\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs) #filtro original=64\n",
    "    c1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c1) #filtro original=64\n",
    "    p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(p1) #filtro original=128\n",
    "    c2 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c2) #filtro original=128\n",
    "    p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(p2) #filtro original=256\n",
    "    c3 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(c3) #filtro original=256\n",
    "    \n",
    "    # Decoder\n",
    "    u4 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c3) #filtro original=128\n",
    "    u4 = tf.keras.layers.concatenate([u4, c2])\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(u4) #filtro original=128\n",
    "    c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(c4) #filtro original=128\n",
    "    \n",
    "    u5 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c4) #filtro original=64\n",
    "    u5 = tf.keras.layers.concatenate([u5, c1])\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(u5) #filtro original=64\n",
    "    c5 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(c5) #filtro original=64\n",
    "    \n",
    "    outputs = tf.keras.layers.Conv2D(2, (1, 1), activation='linear')(c5)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definir la metrica NMSE ajustada para utilizar la varianza de los valores verdaderos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmse(y_true, y_pred):\n",
    "    mse = tf.keras.backend.mean(tf.keras.backend.square(y_true - y_pred))\n",
    "    var_true = tf.keras.backend.var(y_true)\n",
    "    return mse / var_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**HIPERPARAMETROS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 300\n",
    "batchsize = 8\n",
    "learning_rate = 0.0001\n",
    "#l2_lambda = 0.01\n",
    "validation_split = 0.2 # 70% entrenamiento & 30% validacion\n",
    "\n",
    "\n",
    " # alpha: el lr min al que llegara el decaimiento sera el 10% del lr inicia\n",
    "#alpha = 0.1\n",
    "# decay steps: Numero de pasos de entrenamiento tras los cuales el learning rate decaera desde su valor inicial hasta el valor final determinado por alpha\n",
    "#decay_steps = 300#(int(X.shape[0]/batchsize))*max_epoch \n",
    "#print(\"Total pasos de decaimiento ->\",decay_steps, \"pasos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CREACIÓN DEL MODELO U-NET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1:]  # forma del input a entrar. en este caso esta forma debe coincidir con las matrices que entran a la red tensor X = [#inputs, columnas, filas, canales]. Se omite #inputs\n",
    "model = unet_model(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DEFINICION DE LA FUNCION DE DECAIMIENTO, ALGORITMO OPTIMIZADOR, FUNCION DE PERDIDA Y METRICA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#funcion decaimiento de coseno\n",
    "decay_cosine = tf.keras.experimental.CosineDecay(learning_rate, decay_steps)\n",
    "def lr_schedule(X):\n",
    "    return float(decay_cosine(X))\n",
    "    \n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[nmse])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################<br>\n",
    "#########################################################################################################<br>\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTRENAMIENTO DE LA RED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "5/5 [==============================] - 29s 5s/step - loss: 0.3678 - nmse: 0.9124 - val_loss: 0.3041 - val_nmse: 0.8191\n",
      "Epoch 2/300\n",
      "5/5 [==============================] - 27s 6s/step - loss: 0.3387 - nmse: 0.8419 - val_loss: 0.3037 - val_nmse: 0.8178\n",
      "Epoch 3/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.3291 - nmse: 0.8185 - val_loss: 0.2870 - val_nmse: 0.7732\n",
      "Epoch 4/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.3216 - nmse: 0.7988 - val_loss: 0.2834 - val_nmse: 0.7633\n",
      "Epoch 5/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.3136 - nmse: 0.7798 - val_loss: 0.2715 - val_nmse: 0.7300\n",
      "Epoch 6/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.3046 - nmse: 0.7555 - val_loss: 0.2629 - val_nmse: 0.7065\n",
      "Epoch 7/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.2920 - nmse: 0.7255 - val_loss: 0.2481 - val_nmse: 0.6635\n",
      "Epoch 8/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.2767 - nmse: 0.6869 - val_loss: 0.2338 - val_nmse: 0.6220\n",
      "Epoch 9/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.2805 - nmse: 0.6946 - val_loss: 0.2561 - val_nmse: 0.6828\n",
      "Epoch 10/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.2810 - nmse: 0.6986 - val_loss: 0.2344 - val_nmse: 0.6281\n",
      "Epoch 11/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.2611 - nmse: 0.6488 - val_loss: 0.2138 - val_nmse: 0.5682\n",
      "Epoch 12/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.2421 - nmse: 0.5981 - val_loss: 0.1969 - val_nmse: 0.5212\n",
      "Epoch 13/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.2250 - nmse: 0.5562 - val_loss: 0.1794 - val_nmse: 0.4737\n",
      "Epoch 14/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.2113 - nmse: 0.5211 - val_loss: 0.1700 - val_nmse: 0.4501\n",
      "Epoch 15/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1985 - nmse: 0.4921 - val_loss: 0.1560 - val_nmse: 0.4126\n",
      "Epoch 16/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1846 - nmse: 0.4577 - val_loss: 0.1426 - val_nmse: 0.3779\n",
      "Epoch 17/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1717 - nmse: 0.4223 - val_loss: 0.1340 - val_nmse: 0.3520\n",
      "Epoch 18/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1655 - nmse: 0.4105 - val_loss: 0.1280 - val_nmse: 0.3380\n",
      "Epoch 19/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1586 - nmse: 0.3906 - val_loss: 0.1256 - val_nmse: 0.3311\n",
      "Epoch 20/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1526 - nmse: 0.3790 - val_loss: 0.1189 - val_nmse: 0.3129\n",
      "Epoch 21/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.1475 - nmse: 0.3657 - val_loss: 0.1148 - val_nmse: 0.3020\n",
      "Epoch 22/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.1416 - nmse: 0.3486 - val_loss: 0.1097 - val_nmse: 0.2889\n",
      "Epoch 23/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.1364 - nmse: 0.3390 - val_loss: 0.1063 - val_nmse: 0.2794\n",
      "Epoch 24/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1330 - nmse: 0.3304 - val_loss: 0.1032 - val_nmse: 0.2712\n",
      "Epoch 25/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1292 - nmse: 0.3176 - val_loss: 0.1025 - val_nmse: 0.2687\n",
      "Epoch 26/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1267 - nmse: 0.3145 - val_loss: 0.1004 - val_nmse: 0.2627\n",
      "Epoch 27/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1249 - nmse: 0.3088 - val_loss: 0.0996 - val_nmse: 0.2616\n",
      "Epoch 28/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1211 - nmse: 0.2962 - val_loss: 0.0995 - val_nmse: 0.2604\n",
      "Epoch 29/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1171 - nmse: 0.2871 - val_loss: 0.0972 - val_nmse: 0.2531\n",
      "Epoch 30/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1134 - nmse: 0.2809 - val_loss: 0.0992 - val_nmse: 0.2577\n",
      "Epoch 31/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1118 - nmse: 0.2775 - val_loss: 0.0990 - val_nmse: 0.2572\n",
      "Epoch 32/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1088 - nmse: 0.2703 - val_loss: 0.0995 - val_nmse: 0.2579\n",
      "Epoch 33/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.1062 - nmse: 0.2631 - val_loss: 0.1032 - val_nmse: 0.2672\n",
      "Epoch 34/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.1044 - nmse: 0.2590 - val_loss: 0.1001 - val_nmse: 0.2606\n",
      "Epoch 35/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0996 - nmse: 0.2477 - val_loss: 0.1047 - val_nmse: 0.2720\n",
      "Epoch 36/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0950 - nmse: 0.2353 - val_loss: 0.1027 - val_nmse: 0.2664\n",
      "Epoch 37/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0915 - nmse: 0.2252 - val_loss: 0.1021 - val_nmse: 0.2653\n",
      "Epoch 38/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0878 - nmse: 0.2180 - val_loss: 0.1080 - val_nmse: 0.2789\n",
      "Epoch 39/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0814 - nmse: 0.2019 - val_loss: 0.1017 - val_nmse: 0.2623\n",
      "Epoch 40/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0764 - nmse: 0.1895 - val_loss: 0.1043 - val_nmse: 0.2696\n",
      "Epoch 41/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0696 - nmse: 0.1730 - val_loss: 0.1097 - val_nmse: 0.2825\n",
      "Epoch 42/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0654 - nmse: 0.1621 - val_loss: 0.1111 - val_nmse: 0.2846\n",
      "Epoch 43/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0678 - nmse: 0.1674 - val_loss: 0.1066 - val_nmse: 0.2735\n",
      "Epoch 44/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0634 - nmse: 0.1574 - val_loss: 0.1119 - val_nmse: 0.2866\n",
      "Epoch 45/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0577 - nmse: 0.1431 - val_loss: 0.1108 - val_nmse: 0.2865\n",
      "Epoch 46/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0538 - nmse: 0.1336 - val_loss: 0.1107 - val_nmse: 0.2847\n",
      "Epoch 47/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0499 - nmse: 0.1240 - val_loss: 0.1121 - val_nmse: 0.2887\n",
      "Epoch 48/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0467 - nmse: 0.1160 - val_loss: 0.1123 - val_nmse: 0.2906\n",
      "Epoch 49/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0432 - nmse: 0.1071 - val_loss: 0.1178 - val_nmse: 0.3043\n",
      "Epoch 50/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0407 - nmse: 0.1012 - val_loss: 0.1215 - val_nmse: 0.3128\n",
      "Epoch 51/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0386 - nmse: 0.0956 - val_loss: 0.1165 - val_nmse: 0.3004\n",
      "Epoch 52/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0359 - nmse: 0.0890 - val_loss: 0.1190 - val_nmse: 0.3054\n",
      "Epoch 53/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0339 - nmse: 0.0841 - val_loss: 0.1179 - val_nmse: 0.3030\n",
      "Epoch 54/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0321 - nmse: 0.0797 - val_loss: 0.1171 - val_nmse: 0.3020\n",
      "Epoch 55/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0306 - nmse: 0.0762 - val_loss: 0.1176 - val_nmse: 0.3038\n",
      "Epoch 56/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0292 - nmse: 0.0727 - val_loss: 0.1193 - val_nmse: 0.3061\n",
      "Epoch 57/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0293 - nmse: 0.0728 - val_loss: 0.1195 - val_nmse: 0.3077\n",
      "Epoch 58/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0277 - nmse: 0.0690 - val_loss: 0.1217 - val_nmse: 0.3139\n",
      "Epoch 59/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0270 - nmse: 0.0671 - val_loss: 0.1218 - val_nmse: 0.3145\n",
      "Epoch 60/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0244 - nmse: 0.0607 - val_loss: 0.1199 - val_nmse: 0.3087\n",
      "Epoch 61/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0237 - nmse: 0.0590 - val_loss: 0.1166 - val_nmse: 0.2996\n",
      "Epoch 62/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0225 - nmse: 0.0558 - val_loss: 0.1199 - val_nmse: 0.3085\n",
      "Epoch 63/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0219 - nmse: 0.0543 - val_loss: 0.1200 - val_nmse: 0.3090\n",
      "Epoch 64/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0201 - nmse: 0.0500 - val_loss: 0.1198 - val_nmse: 0.3080\n",
      "Epoch 65/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0211 - nmse: 0.0525 - val_loss: 0.1154 - val_nmse: 0.2969\n",
      "Epoch 66/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0220 - nmse: 0.0546 - val_loss: 0.1201 - val_nmse: 0.3085\n",
      "Epoch 67/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0210 - nmse: 0.0521 - val_loss: 0.1196 - val_nmse: 0.3078\n",
      "Epoch 68/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0189 - nmse: 0.0470 - val_loss: 0.1175 - val_nmse: 0.3028\n",
      "Epoch 69/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0178 - nmse: 0.0443 - val_loss: 0.1187 - val_nmse: 0.3045\n",
      "Epoch 70/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0170 - nmse: 0.0424 - val_loss: 0.1197 - val_nmse: 0.3077\n",
      "Epoch 71/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0164 - nmse: 0.0407 - val_loss: 0.1187 - val_nmse: 0.3050\n",
      "Epoch 72/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0157 - nmse: 0.0392 - val_loss: 0.1216 - val_nmse: 0.3121\n",
      "Epoch 73/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0156 - nmse: 0.0388 - val_loss: 0.1203 - val_nmse: 0.3078\n",
      "Epoch 74/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0150 - nmse: 0.0374 - val_loss: 0.1191 - val_nmse: 0.3059\n",
      "Epoch 75/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0146 - nmse: 0.0362 - val_loss: 0.1211 - val_nmse: 0.3113\n",
      "Epoch 76/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0141 - nmse: 0.0351 - val_loss: 0.1197 - val_nmse: 0.3080\n",
      "Epoch 77/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0147 - nmse: 0.0366 - val_loss: 0.1200 - val_nmse: 0.3102\n",
      "Epoch 78/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0145 - nmse: 0.0361 - val_loss: 0.1172 - val_nmse: 0.3015\n",
      "Epoch 79/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0141 - nmse: 0.0352 - val_loss: 0.1228 - val_nmse: 0.3148\n",
      "Epoch 80/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0141 - nmse: 0.0351 - val_loss: 0.1185 - val_nmse: 0.3051\n",
      "Epoch 81/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0132 - nmse: 0.0329 - val_loss: 0.1232 - val_nmse: 0.3169\n",
      "Epoch 82/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0128 - nmse: 0.0319 - val_loss: 0.1194 - val_nmse: 0.3071\n",
      "Epoch 83/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0126 - nmse: 0.0312 - val_loss: 0.1228 - val_nmse: 0.3156\n",
      "Epoch 84/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0128 - nmse: 0.0317 - val_loss: 0.1204 - val_nmse: 0.3090\n",
      "Epoch 85/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0120 - nmse: 0.0299 - val_loss: 0.1202 - val_nmse: 0.3090\n",
      "Epoch 86/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0118 - nmse: 0.0292 - val_loss: 0.1249 - val_nmse: 0.3219\n",
      "Epoch 87/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0129 - nmse: 0.0321 - val_loss: 0.1220 - val_nmse: 0.3140\n",
      "Epoch 88/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0126 - nmse: 0.0314 - val_loss: 0.1219 - val_nmse: 0.3135\n",
      "Epoch 89/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0125 - nmse: 0.0312 - val_loss: 0.1203 - val_nmse: 0.3099\n",
      "Epoch 90/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0117 - nmse: 0.0290 - val_loss: 0.1210 - val_nmse: 0.3117\n",
      "Epoch 91/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0105 - nmse: 0.0262 - val_loss: 0.1196 - val_nmse: 0.3074\n",
      "Epoch 92/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0102 - nmse: 0.0255 - val_loss: 0.1208 - val_nmse: 0.3115\n",
      "Epoch 93/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0099 - nmse: 0.0245 - val_loss: 0.1212 - val_nmse: 0.3113\n",
      "Epoch 94/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0098 - nmse: 0.0243 - val_loss: 0.1231 - val_nmse: 0.3177\n",
      "Epoch 95/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0116 - nmse: 0.0288 - val_loss: 0.1190 - val_nmse: 0.3061\n",
      "Epoch 96/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0105 - nmse: 0.0260 - val_loss: 0.1248 - val_nmse: 0.3217\n",
      "Epoch 97/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0108 - nmse: 0.0268 - val_loss: 0.1191 - val_nmse: 0.3066\n",
      "Epoch 98/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0097 - nmse: 0.0242 - val_loss: 0.1195 - val_nmse: 0.3076\n",
      "Epoch 99/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0095 - nmse: 0.0236 - val_loss: 0.1237 - val_nmse: 0.3197\n",
      "Epoch 100/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0094 - nmse: 0.0233 - val_loss: 0.1221 - val_nmse: 0.3150\n",
      "Epoch 101/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0085 - nmse: 0.0213 - val_loss: 0.1208 - val_nmse: 0.3113\n",
      "Epoch 102/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0081 - nmse: 0.0200 - val_loss: 0.1208 - val_nmse: 0.3120\n",
      "Epoch 103/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0080 - nmse: 0.0199 - val_loss: 0.1222 - val_nmse: 0.3147\n",
      "Epoch 104/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0077 - nmse: 0.0190 - val_loss: 0.1197 - val_nmse: 0.3091\n",
      "Epoch 105/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0074 - nmse: 0.0184 - val_loss: 0.1212 - val_nmse: 0.3120\n",
      "Epoch 106/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0071 - nmse: 0.0177 - val_loss: 0.1202 - val_nmse: 0.3096\n",
      "Epoch 107/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0070 - nmse: 0.0175 - val_loss: 0.1213 - val_nmse: 0.3132\n",
      "Epoch 108/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0076 - nmse: 0.0189 - val_loss: 0.1207 - val_nmse: 0.3111\n",
      "Epoch 109/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0072 - nmse: 0.0180 - val_loss: 0.1221 - val_nmse: 0.3151\n",
      "Epoch 110/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0072 - nmse: 0.0179 - val_loss: 0.1220 - val_nmse: 0.3150\n",
      "Epoch 111/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0072 - nmse: 0.0181 - val_loss: 0.1237 - val_nmse: 0.3181\n",
      "Epoch 112/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0074 - nmse: 0.0185 - val_loss: 0.1219 - val_nmse: 0.3143\n",
      "Epoch 113/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0068 - nmse: 0.0168 - val_loss: 0.1245 - val_nmse: 0.3209\n",
      "Epoch 114/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0069 - nmse: 0.0171 - val_loss: 0.1214 - val_nmse: 0.3130\n",
      "Epoch 115/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0068 - nmse: 0.0168 - val_loss: 0.1221 - val_nmse: 0.3153\n",
      "Epoch 116/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0069 - nmse: 0.0171 - val_loss: 0.1207 - val_nmse: 0.3119\n",
      "Epoch 117/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0067 - nmse: 0.0167 - val_loss: 0.1223 - val_nmse: 0.3161\n",
      "Epoch 118/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0067 - nmse: 0.0166 - val_loss: 0.1227 - val_nmse: 0.3166\n",
      "Epoch 119/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0066 - nmse: 0.0164 - val_loss: 0.1235 - val_nmse: 0.3191\n",
      "Epoch 120/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0072 - nmse: 0.0178 - val_loss: 0.1240 - val_nmse: 0.3202\n",
      "Epoch 121/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0082 - nmse: 0.0204 - val_loss: 0.1216 - val_nmse: 0.3139\n",
      "Epoch 122/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0068 - nmse: 0.0169 - val_loss: 0.1229 - val_nmse: 0.3174\n",
      "Epoch 123/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0068 - nmse: 0.0169 - val_loss: 0.1221 - val_nmse: 0.3153\n",
      "Epoch 124/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0067 - nmse: 0.0166 - val_loss: 0.1235 - val_nmse: 0.3188\n",
      "Epoch 125/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0066 - nmse: 0.0165 - val_loss: 0.1221 - val_nmse: 0.3151\n",
      "Epoch 126/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0064 - nmse: 0.0161 - val_loss: 0.1263 - val_nmse: 0.3262\n",
      "Epoch 127/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0066 - nmse: 0.0164 - val_loss: 0.1218 - val_nmse: 0.3151\n",
      "Epoch 128/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0079 - nmse: 0.0197 - val_loss: 0.1201 - val_nmse: 0.3111\n",
      "Epoch 129/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0087 - nmse: 0.0218 - val_loss: 0.1301 - val_nmse: 0.3361\n",
      "Epoch 130/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0084 - nmse: 0.0208 - val_loss: 0.1226 - val_nmse: 0.3176\n",
      "Epoch 131/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0071 - nmse: 0.0175 - val_loss: 0.1205 - val_nmse: 0.3115\n",
      "Epoch 132/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0061 - nmse: 0.0151 - val_loss: 0.1213 - val_nmse: 0.3134\n",
      "Epoch 133/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0058 - nmse: 0.0144 - val_loss: 0.1235 - val_nmse: 0.3193\n",
      "Epoch 134/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0055 - nmse: 0.0138 - val_loss: 0.1227 - val_nmse: 0.3177\n",
      "Epoch 135/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0052 - nmse: 0.0129 - val_loss: 0.1216 - val_nmse: 0.3140\n",
      "Epoch 136/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0050 - nmse: 0.0126 - val_loss: 0.1221 - val_nmse: 0.3151\n",
      "Epoch 137/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0049 - nmse: 0.0122 - val_loss: 0.1208 - val_nmse: 0.3115\n",
      "Epoch 138/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0049 - nmse: 0.0122 - val_loss: 0.1230 - val_nmse: 0.3181\n",
      "Epoch 139/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0047 - nmse: 0.0118 - val_loss: 0.1205 - val_nmse: 0.3110\n",
      "Epoch 140/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0048 - nmse: 0.0119 - val_loss: 0.1221 - val_nmse: 0.3151\n",
      "Epoch 141/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0046 - nmse: 0.0114 - val_loss: 0.1220 - val_nmse: 0.3153\n",
      "Epoch 142/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0045 - nmse: 0.0112 - val_loss: 0.1222 - val_nmse: 0.3155\n",
      "Epoch 143/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0050 - nmse: 0.0125 - val_loss: 0.1220 - val_nmse: 0.3150\n",
      "Epoch 144/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0046 - nmse: 0.0113 - val_loss: 0.1230 - val_nmse: 0.3179\n",
      "Epoch 145/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0045 - nmse: 0.0113 - val_loss: 0.1222 - val_nmse: 0.3160\n",
      "Epoch 146/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0046 - nmse: 0.0113 - val_loss: 0.1219 - val_nmse: 0.3150\n",
      "Epoch 147/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0047 - nmse: 0.0118 - val_loss: 0.1228 - val_nmse: 0.3172\n",
      "Epoch 148/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0044 - nmse: 0.0111 - val_loss: 0.1219 - val_nmse: 0.3148\n",
      "Epoch 149/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0056 - nmse: 0.0139 - val_loss: 0.1209 - val_nmse: 0.3116\n",
      "Epoch 150/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0051 - nmse: 0.0128 - val_loss: 0.1216 - val_nmse: 0.3140\n",
      "Epoch 151/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0052 - nmse: 0.0130 - val_loss: 0.1209 - val_nmse: 0.3119\n",
      "Epoch 152/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0052 - nmse: 0.0130 - val_loss: 0.1219 - val_nmse: 0.3142\n",
      "Epoch 153/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0053 - nmse: 0.0133 - val_loss: 0.1225 - val_nmse: 0.3159\n",
      "Epoch 154/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0060 - nmse: 0.0149 - val_loss: 0.1224 - val_nmse: 0.3159\n",
      "Epoch 155/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0071 - nmse: 0.0179 - val_loss: 0.1229 - val_nmse: 0.3178\n",
      "Epoch 156/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0061 - nmse: 0.0151 - val_loss: 0.1226 - val_nmse: 0.3165\n",
      "Epoch 157/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0055 - nmse: 0.0136 - val_loss: 0.1213 - val_nmse: 0.3139\n",
      "Epoch 158/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0051 - nmse: 0.0128 - val_loss: 0.1201 - val_nmse: 0.3094\n",
      "Epoch 159/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0055 - nmse: 0.0137 - val_loss: 0.1232 - val_nmse: 0.3170\n",
      "Epoch 160/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0049 - nmse: 0.0124 - val_loss: 0.1217 - val_nmse: 0.3142\n",
      "Epoch 161/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0049 - nmse: 0.0121 - val_loss: 0.1245 - val_nmse: 0.3205\n",
      "Epoch 162/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0050 - nmse: 0.0125 - val_loss: 0.1215 - val_nmse: 0.3140\n",
      "Epoch 163/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0058 - nmse: 0.0145 - val_loss: 0.1203 - val_nmse: 0.3102\n",
      "Epoch 164/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0056 - nmse: 0.0138 - val_loss: 0.1247 - val_nmse: 0.3225\n",
      "Epoch 165/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0054 - nmse: 0.0135 - val_loss: 0.1205 - val_nmse: 0.3115\n",
      "Epoch 166/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0047 - nmse: 0.0118 - val_loss: 0.1219 - val_nmse: 0.3151\n",
      "Epoch 167/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0045 - nmse: 0.0112 - val_loss: 0.1238 - val_nmse: 0.3202\n",
      "Epoch 168/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0044 - nmse: 0.0109 - val_loss: 0.1213 - val_nmse: 0.3137\n",
      "Epoch 169/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0043 - nmse: 0.0107 - val_loss: 0.1219 - val_nmse: 0.3151\n",
      "Epoch 170/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0041 - nmse: 0.0103 - val_loss: 0.1228 - val_nmse: 0.3177\n",
      "Epoch 171/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0039 - nmse: 0.0096 - val_loss: 0.1215 - val_nmse: 0.3143\n",
      "Epoch 172/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0037 - nmse: 0.0093 - val_loss: 0.1217 - val_nmse: 0.3147\n",
      "Epoch 173/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0037 - nmse: 0.0092 - val_loss: 0.1215 - val_nmse: 0.3139\n",
      "Epoch 174/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0034 - nmse: 0.0085 - val_loss: 0.1222 - val_nmse: 0.3158\n",
      "Epoch 175/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0034 - nmse: 0.0084 - val_loss: 0.1214 - val_nmse: 0.3137\n",
      "Epoch 176/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0034 - nmse: 0.0083 - val_loss: 0.1228 - val_nmse: 0.3168\n",
      "Epoch 177/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0033 - nmse: 0.0081 - val_loss: 0.1205 - val_nmse: 0.3109\n",
      "Epoch 178/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0032 - nmse: 0.0081 - val_loss: 0.1210 - val_nmse: 0.3125\n",
      "Epoch 179/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0033 - nmse: 0.0083 - val_loss: 0.1220 - val_nmse: 0.3150\n",
      "Epoch 180/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0032 - nmse: 0.0080 - val_loss: 0.1206 - val_nmse: 0.3115\n",
      "Epoch 181/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0031 - nmse: 0.0077 - val_loss: 0.1212 - val_nmse: 0.3134\n",
      "Epoch 182/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0031 - nmse: 0.0078 - val_loss: 0.1207 - val_nmse: 0.3122\n",
      "Epoch 183/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0032 - nmse: 0.0079 - val_loss: 0.1215 - val_nmse: 0.3140\n",
      "Epoch 184/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0031 - nmse: 0.0076 - val_loss: 0.1215 - val_nmse: 0.3136\n",
      "Epoch 185/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0029 - nmse: 0.0073 - val_loss: 0.1225 - val_nmse: 0.3164\n",
      "Epoch 186/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0029 - nmse: 0.0073 - val_loss: 0.1209 - val_nmse: 0.3127\n",
      "Epoch 187/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0029 - nmse: 0.0071 - val_loss: 0.1224 - val_nmse: 0.3166\n",
      "Epoch 188/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0028 - nmse: 0.0071 - val_loss: 0.1213 - val_nmse: 0.3137\n",
      "Epoch 189/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0028 - nmse: 0.0070 - val_loss: 0.1224 - val_nmse: 0.3161\n",
      "Epoch 190/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0034 - nmse: 0.0084 - val_loss: 0.1221 - val_nmse: 0.3153\n",
      "Epoch 191/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0030 - nmse: 0.0074 - val_loss: 0.1213 - val_nmse: 0.3139\n",
      "Epoch 192/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0032 - nmse: 0.0079 - val_loss: 0.1219 - val_nmse: 0.3156\n",
      "Epoch 193/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0036 - nmse: 0.0090 - val_loss: 0.1227 - val_nmse: 0.3173\n",
      "Epoch 194/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0044 - nmse: 0.0110 - val_loss: 0.1214 - val_nmse: 0.3130\n",
      "Epoch 195/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0036 - nmse: 0.0090 - val_loss: 0.1227 - val_nmse: 0.3171\n",
      "Epoch 196/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0032 - nmse: 0.0080 - val_loss: 0.1217 - val_nmse: 0.3144\n",
      "Epoch 197/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0034 - nmse: 0.0085 - val_loss: 0.1222 - val_nmse: 0.3159\n",
      "Epoch 198/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0033 - nmse: 0.0084 - val_loss: 0.1225 - val_nmse: 0.3167\n",
      "Epoch 199/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0036 - nmse: 0.0090 - val_loss: 0.1239 - val_nmse: 0.3202\n",
      "Epoch 200/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0041 - nmse: 0.0101 - val_loss: 0.1227 - val_nmse: 0.3172\n",
      "Epoch 201/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0037 - nmse: 0.0093 - val_loss: 0.1223 - val_nmse: 0.3159\n",
      "Epoch 202/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0034 - nmse: 0.0085 - val_loss: 0.1241 - val_nmse: 0.3204\n",
      "Epoch 203/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0032 - nmse: 0.0080 - val_loss: 0.1218 - val_nmse: 0.3159\n",
      "Epoch 204/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0036 - nmse: 0.0091 - val_loss: 0.1232 - val_nmse: 0.3185\n",
      "Epoch 205/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0034 - nmse: 0.0083 - val_loss: 0.1210 - val_nmse: 0.3130\n",
      "Epoch 206/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0030 - nmse: 0.0074 - val_loss: 0.1212 - val_nmse: 0.3128\n",
      "Epoch 207/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0031 - nmse: 0.0078 - val_loss: 0.1218 - val_nmse: 0.3154\n",
      "Epoch 208/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0030 - nmse: 0.0076 - val_loss: 0.1213 - val_nmse: 0.3136\n",
      "Epoch 209/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0027 - nmse: 0.0068 - val_loss: 0.1217 - val_nmse: 0.3149\n",
      "Epoch 210/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0028 - nmse: 0.0069 - val_loss: 0.1216 - val_nmse: 0.3145\n",
      "Epoch 211/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0026 - nmse: 0.0066 - val_loss: 0.1224 - val_nmse: 0.3166\n",
      "Epoch 212/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0037 - nmse: 0.0093 - val_loss: 0.1221 - val_nmse: 0.3159\n",
      "Epoch 213/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0032 - nmse: 0.0080 - val_loss: 0.1220 - val_nmse: 0.3151\n",
      "Epoch 214/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0030 - nmse: 0.0075 - val_loss: 0.1219 - val_nmse: 0.3157\n",
      "Epoch 215/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0033 - nmse: 0.0085 - val_loss: 0.1233 - val_nmse: 0.3187\n",
      "Epoch 216/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0032 - nmse: 0.0079 - val_loss: 0.1212 - val_nmse: 0.3136\n",
      "Epoch 217/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0028 - nmse: 0.0070 - val_loss: 0.1223 - val_nmse: 0.3165\n",
      "Epoch 218/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0029 - nmse: 0.0072 - val_loss: 0.1219 - val_nmse: 0.3156\n",
      "Epoch 219/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0027 - nmse: 0.0067 - val_loss: 0.1217 - val_nmse: 0.3149\n",
      "Epoch 220/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0027 - nmse: 0.0068 - val_loss: 0.1221 - val_nmse: 0.3157\n",
      "Epoch 221/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0027 - nmse: 0.0066 - val_loss: 0.1227 - val_nmse: 0.3177\n",
      "Epoch 222/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0027 - nmse: 0.0066 - val_loss: 0.1217 - val_nmse: 0.3144\n",
      "Epoch 223/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0026 - nmse: 0.0064 - val_loss: 0.1218 - val_nmse: 0.3151\n",
      "Epoch 224/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0024 - nmse: 0.0061 - val_loss: 0.1225 - val_nmse: 0.3168\n",
      "Epoch 225/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0025 - nmse: 0.0062 - val_loss: 0.1217 - val_nmse: 0.3151\n",
      "Epoch 226/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0024 - nmse: 0.0060 - val_loss: 0.1222 - val_nmse: 0.3161\n",
      "Epoch 227/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0025 - nmse: 0.0063 - val_loss: 0.1223 - val_nmse: 0.3161\n",
      "Epoch 228/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0024 - nmse: 0.0060 - val_loss: 0.1221 - val_nmse: 0.3158\n",
      "Epoch 229/300\n",
      "5/5 [==============================] - 26s 5s/step - loss: 0.0022 - nmse: 0.0056 - val_loss: 0.1222 - val_nmse: 0.3159\n",
      "Epoch 230/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0024 - nmse: 0.0060 - val_loss: 0.1210 - val_nmse: 0.3132\n",
      "Epoch 231/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0024 - nmse: 0.0060 - val_loss: 0.1224 - val_nmse: 0.3162\n",
      "Epoch 232/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0024 - nmse: 0.0060 - val_loss: 0.1216 - val_nmse: 0.3149\n",
      "Epoch 233/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0023 - nmse: 0.0057 - val_loss: 0.1217 - val_nmse: 0.3149\n",
      "Epoch 234/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0024 - nmse: 0.0059 - val_loss: 0.1215 - val_nmse: 0.3147\n",
      "Epoch 235/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0026 - nmse: 0.0065 - val_loss: 0.1215 - val_nmse: 0.3144\n",
      "Epoch 236/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0027 - nmse: 0.0066 - val_loss: 0.1216 - val_nmse: 0.3159\n",
      "Epoch 237/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0029 - nmse: 0.0073 - val_loss: 0.1225 - val_nmse: 0.3171\n",
      "Epoch 238/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0035 - nmse: 0.0088 - val_loss: 0.1215 - val_nmse: 0.3153\n",
      "Epoch 239/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0040 - nmse: 0.0100 - val_loss: 0.1229 - val_nmse: 0.3182\n",
      "Epoch 240/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0034 - nmse: 0.0086 - val_loss: 0.1218 - val_nmse: 0.3154\n",
      "Epoch 241/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0030 - nmse: 0.0074 - val_loss: 0.1210 - val_nmse: 0.3133\n",
      "Epoch 242/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0031 - nmse: 0.0077 - val_loss: 0.1218 - val_nmse: 0.3150\n",
      "Epoch 243/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0028 - nmse: 0.0069 - val_loss: 0.1222 - val_nmse: 0.3164\n",
      "Epoch 244/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0031 - nmse: 0.0076 - val_loss: 0.1213 - val_nmse: 0.3144\n",
      "Epoch 245/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0038 - nmse: 0.0094 - val_loss: 0.1230 - val_nmse: 0.3181\n",
      "Epoch 246/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0030 - nmse: 0.0076 - val_loss: 0.1205 - val_nmse: 0.3120\n",
      "Epoch 247/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0029 - nmse: 0.0073 - val_loss: 0.1210 - val_nmse: 0.3132\n",
      "Epoch 248/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0026 - nmse: 0.0064 - val_loss: 0.1215 - val_nmse: 0.3146\n",
      "Epoch 249/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0023 - nmse: 0.0057 - val_loss: 0.1211 - val_nmse: 0.3136\n",
      "Epoch 250/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0023 - nmse: 0.0058 - val_loss: 0.1218 - val_nmse: 0.3152\n",
      "Epoch 251/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0022 - nmse: 0.0056 - val_loss: 0.1211 - val_nmse: 0.3136\n",
      "Epoch 252/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0022 - nmse: 0.0054 - val_loss: 0.1210 - val_nmse: 0.3135\n",
      "Epoch 253/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0022 - nmse: 0.0054 - val_loss: 0.1215 - val_nmse: 0.3148\n",
      "Epoch 254/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0022 - nmse: 0.0056 - val_loss: 0.1214 - val_nmse: 0.3145\n",
      "Epoch 255/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0022 - nmse: 0.0056 - val_loss: 0.1218 - val_nmse: 0.3152\n",
      "Epoch 256/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0026 - nmse: 0.0065 - val_loss: 0.1211 - val_nmse: 0.3135\n",
      "Epoch 257/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0024 - nmse: 0.0059 - val_loss: 0.1206 - val_nmse: 0.3122\n",
      "Epoch 258/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0022 - nmse: 0.0055 - val_loss: 0.1217 - val_nmse: 0.3152\n",
      "Epoch 259/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0022 - nmse: 0.0056 - val_loss: 0.1210 - val_nmse: 0.3135\n",
      "Epoch 260/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0022 - nmse: 0.0056 - val_loss: 0.1217 - val_nmse: 0.3151\n",
      "Epoch 261/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0023 - nmse: 0.0058 - val_loss: 0.1209 - val_nmse: 0.3133\n",
      "Epoch 262/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0025 - nmse: 0.0062 - val_loss: 0.1215 - val_nmse: 0.3141\n",
      "Epoch 263/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0025 - nmse: 0.0063 - val_loss: 0.1228 - val_nmse: 0.3175\n",
      "Epoch 264/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0028 - nmse: 0.0069 - val_loss: 0.1224 - val_nmse: 0.3165\n",
      "Epoch 265/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0025 - nmse: 0.0063 - val_loss: 0.1208 - val_nmse: 0.3123\n",
      "Epoch 266/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0029 - nmse: 0.0073 - val_loss: 0.1230 - val_nmse: 0.3185\n",
      "Epoch 267/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0027 - nmse: 0.0067 - val_loss: 0.1213 - val_nmse: 0.3140\n",
      "Epoch 268/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0026 - nmse: 0.0065 - val_loss: 0.1209 - val_nmse: 0.3130\n",
      "Epoch 269/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0027 - nmse: 0.0067 - val_loss: 0.1215 - val_nmse: 0.3140\n",
      "Epoch 270/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0027 - nmse: 0.0067 - val_loss: 0.1203 - val_nmse: 0.3119\n",
      "Epoch 271/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0025 - nmse: 0.0063 - val_loss: 0.1218 - val_nmse: 0.3155\n",
      "Epoch 272/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0028 - nmse: 0.0069 - val_loss: 0.1204 - val_nmse: 0.3118\n",
      "Epoch 273/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0029 - nmse: 0.0072 - val_loss: 0.1211 - val_nmse: 0.3140\n",
      "Epoch 274/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0029 - nmse: 0.0072 - val_loss: 0.1218 - val_nmse: 0.3144\n",
      "Epoch 275/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0032 - nmse: 0.0079 - val_loss: 0.1206 - val_nmse: 0.3133\n",
      "Epoch 276/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0035 - nmse: 0.0086 - val_loss: 0.1214 - val_nmse: 0.3147\n",
      "Epoch 277/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0028 - nmse: 0.0070 - val_loss: 0.1204 - val_nmse: 0.3110\n",
      "Epoch 278/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0025 - nmse: 0.0062 - val_loss: 0.1191 - val_nmse: 0.3081\n",
      "Epoch 279/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0025 - nmse: 0.0061 - val_loss: 0.1203 - val_nmse: 0.3117\n",
      "Epoch 280/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0024 - nmse: 0.0059 - val_loss: 0.1213 - val_nmse: 0.3137\n",
      "Epoch 281/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0030 - nmse: 0.0075 - val_loss: 0.1221 - val_nmse: 0.3163\n",
      "Epoch 282/300\n",
      "5/5 [==============================] - 25s 5s/step - loss: 0.0036 - nmse: 0.0088 - val_loss: 0.1196 - val_nmse: 0.3100\n",
      "Epoch 283/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0032 - nmse: 0.0079 - val_loss: 0.1190 - val_nmse: 0.3085\n",
      "Epoch 284/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0032 - nmse: 0.0079 - val_loss: 0.1220 - val_nmse: 0.3157\n",
      "Epoch 285/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0031 - nmse: 0.0077 - val_loss: 0.1203 - val_nmse: 0.3117\n",
      "Epoch 286/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0025 - nmse: 0.0063 - val_loss: 0.1200 - val_nmse: 0.3106\n",
      "Epoch 287/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0024 - nmse: 0.0060 - val_loss: 0.1202 - val_nmse: 0.3114\n",
      "Epoch 288/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0023 - nmse: 0.0056 - val_loss: 0.1193 - val_nmse: 0.3093\n",
      "Epoch 289/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0025 - nmse: 0.0063 - val_loss: 0.1216 - val_nmse: 0.3147\n",
      "Epoch 290/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0025 - nmse: 0.0062 - val_loss: 0.1204 - val_nmse: 0.3118\n",
      "Epoch 291/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0025 - nmse: 0.0061 - val_loss: 0.1201 - val_nmse: 0.3105\n",
      "Epoch 292/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0023 - nmse: 0.0057 - val_loss: 0.1199 - val_nmse: 0.3107\n",
      "Epoch 293/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0020 - nmse: 0.0050 - val_loss: 0.1190 - val_nmse: 0.3082\n",
      "Epoch 294/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0020 - nmse: 0.0050 - val_loss: 0.1199 - val_nmse: 0.3098\n",
      "Epoch 295/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0020 - nmse: 0.0050 - val_loss: 0.1200 - val_nmse: 0.3109\n",
      "Epoch 296/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0020 - nmse: 0.0049 - val_loss: 0.1191 - val_nmse: 0.3083\n",
      "Epoch 297/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0019 - nmse: 0.0047 - val_loss: 0.1196 - val_nmse: 0.3095\n",
      "Epoch 298/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0018 - nmse: 0.0044 - val_loss: 0.1201 - val_nmse: 0.3115\n",
      "Epoch 299/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0017 - nmse: 0.0043 - val_loss: 0.1189 - val_nmse: 0.3079\n",
      "Epoch 300/300\n",
      "5/5 [==============================] - 24s 5s/step - loss: 0.0019 - nmse: 0.0046 - val_loss: 0.1200 - val_nmse: 0.3106\n",
      "Tiempo total de entrenamiento: 122.23 minutos.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#history = model.fit(X, Y, epochs=max_epoch, batch_size=batchsize, callbacks=[lr_scheduler], validation_split=validation_split)\n",
    "history = model.fit(X, Y, epochs=max_epoch, batch_size=batchsize, validation_split=validation_split)\n",
    "end_time = time.time()\n",
    "total_time = end_time - start_time\n",
    "min_time = total_time / 60\n",
    "print(f'Tiempo total de entrenamiento: {min_time:.2f} minutos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#########################################################################################################<br>\n",
    "#########################################################################################################<br>\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizar el NMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['nmse'], label='NMSE (entrenamiento)')\n",
    "plt.plot(history.history['val_nmse'], label='NMSE (validacion)')\n",
    "plt.xlabel('Epoca')\n",
    "plt.ylabel('NMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GUARDAR UN MODELO ESPECÍFICO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio en donde se almacenara el modelo\n",
    "save_dir = 'D:/TT/Memoria/MemoriaCodigoFuentev3/codigo_matlab/codigo_fuente/signals_LDS/' + persona\n",
    "os.makedirs(save_dir, exist_ok=True)  # Crear el directorio si no existe\n",
    "\n",
    "# Nombre del archivo del modelo\n",
    "model_name = 'unet_model_' + lado + 'v2_batch16_epochs250.keras'\n",
    "\n",
    "# Ruta completa del archivo\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Guardar el modelo entrenado\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARGAR UN MODELO ESPECÍFICO**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modelo_cargado = tf.keras.models.load_model('D:/TT/Memoria/waveletycnn/codigo_python/modelos_generados/unet_model_7.keras',\n",
    "                                           custom_objects={'nmse': nmse})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARGAR COEFICIENTES (MATRIZ COMPLEJA) DE LA SEÑALES PAM ORIGINALES T OBTENER CANTIDAD DE MATRICES COMPLEJAS ENCONTRADAS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input_matrix_complex_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/inputs_coeficientes' # coeficientes de senal PAM original (sin ruido) en formato .mat\n",
    "output_matrix_complex_pam_dir = 'D:/TT/Memoria/waveletycnn/codigo_python/inputs_coeficientes_npy' # coeficientes de senal PAM original (sin ruido) en formato .npy\n",
    "os.makedirs(output_matrix_complex_pam_dir, exist_ok=True) # crear directorio \"output_matrix_complex_pam_dir\" si no existe\n",
    "\n",
    "# Se leen la cantidad de coeficientes o matrices complejas de senales PAM encontradas en el directorio \"input_matrix_complex_pam_dir\"\n",
    "total_matrix_complex_pam = sum(1 for filename in os.listdir(input_matrix_complex_pam_dir) if filename.endswith('.mat')) + 1\n",
    "print(\"Total de matrices complejas PAM encontradas -> \", total_matrix_complex_pam - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORMAR A FORMATO .npy LAS MATRICES COMPLEJAS ASOCIADAS A LA SEÑAL ORIGINAL PAM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion para convertir una matriz compleja de .mat a .npy\n",
    "def convert_mat_to_npy_original_signal(input_dir, output_dir, prefix):\n",
    "    for i in range(1, total_matrix_complex_pam):\n",
    "        mat_file = os.path.join(input_dir, f'{prefix}_{i}.mat')\n",
    "        npy_file = os.path.join(output_dir, f'{prefix}_npy_{i}.npy')\n",
    "        \n",
    "        # Cargar el archivo .mat\n",
    "        mat_data = loadmat(mat_file)\n",
    "        \n",
    "        # Extraer la matriz compleja\n",
    "        matrix_key = [key for key in mat_data.keys() if not key.startswith('__')][0]\n",
    "        matrix = mat_data[matrix_key]\n",
    "        \n",
    "        # Guardar la matriz en formato .npy\n",
    "        np.save(npy_file, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir las matrices comlejas de senales PAM originales de formato .mat a .npy\n",
    "convert_mat_to_npy_original_signal(input_matrix_complex_pam_dir, output_matrix_complex_pam_dir, 'matrix_complex_pam_to_predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREDECIR COEFICIENTES DE UNA SEÑAL DE VSC A PARTIR DE COEFICIENTES DE UNA SEÑAL PAM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcion para predecir con el modelo entrenado\n",
    "def predecir_coefs(modelo_cargado, input_data):\n",
    "    coefs_predicted = modelo_cargado.predict(input_data)\n",
    "    return coefs_predicted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listar todos los archivos en el directorio\n",
    "archivos_npy_dir = os.listdir(output_matrix_complex_pam_dir)\n",
    "# Filtrar solo los archivos .npy\n",
    "archivos_npy = [f for f in archivos_npy_dir if f.endswith('.npy')]\n",
    "\n",
    "# Cargar una matriz de entrada para hacer una prediccion \n",
    "# Leer el primer archivo .npy\n",
    "nombre_archivo_pam_npy = archivos_npy[0]\n",
    "archivo_pam_npy_dir = os.path.join(output_matrix_complex_pam_dir, nombre_archivo_pam_npy) # ELEGIR ARCHIVOS NPY A LEER (0, 1, 2, 3, 4, ...)\n",
    "\n",
    "#######################\n",
    "# ENTRADA PARA LA RED:\n",
    "######################\n",
    "input_matrix_pam = np.load(archivo_pam_npy_dir)\n",
    "print(\"Archivo cargado:\", archivo_pam_npy_dir)\n",
    "print(\"formato matrix complex input: \",input_matrix_pam.shape)\n",
    "\n",
    "tensor_input_matrix_pam = np.stack((input_matrix_pam.real, input_matrix_pam.imag), axis=-1)\n",
    "print(\"formato matrix complex input como tensor: \",tensor_input_matrix_pam.shape)\n",
    "\n",
    "# Expandir dimensiones para que coincidan con la forma esperada por el modelo\n",
    "tensor_input_matrix_pam = np.expand_dims(tensor_input_matrix_pam, axis=0)\n",
    "print(\"Formato matrix complex input con dimensión adicional:\", tensor_input_matrix_pam.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REALIZAR PREDICCIÓN (OBTENCIÓN DE COEFICIENTES DE SEÑAL VSC ESTIMADA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Realizar la predicción\n",
    "predicted_output = predecir_coefs(modelo_cargado, tensor_input_matrix_pam)\n",
    "\n",
    "# Mostrar la predicción\n",
    "print(\"Prediccion de la primera muestra de entrada:\")\n",
    "print(predicted_output)\n",
    "print(\"Formato de los coeficientes de la senal VSC estimada: \", predicted_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORMAR LA SALIDA ESTIMADA A UN FORMATO (36, 1024) Y LUEGO DE .npy a .mat**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformar la matriz tensor VSC a una matriz compleja de formato .mat\n",
    "# El tensor tiene la forma (1, 36, 1024, 2) y necesitamos transformarlo a (36, 1024) a matriz compleja\n",
    "complex_matrix_vsc = predicted_output[0, :, :, 0] + 1j * predicted_output[0, :, :, 1]\n",
    "print(\"Formato nuevo:\",complex_matrix_vsc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Especificar la ruta completa del archivo, incluyendo el nombre y la extensión .mat\n",
    "ruta_archivo = \"D:\\TT\\Memoria\\waveletycnn\\codigo_matlab\\codigo_fuente\\coefs_vsc_predicted\\coefs_vsc_predicted.mat\"\n",
    "\n",
    "# Guardar la matriz compleja en el archivo especificado\n",
    "scipy.io.savemat(ruta_archivo, {'complex_matrix_vsc': complex_matrix_vsc})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRANSFORMACIÓN DE COEFICIENTES DE LA SENAL VSC ESTIMADA DE FORMATO .mat a .npy**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GUARDADO DE LA MATRIZ COMPLEJA DE LA VSC ESTIMADA EN UNA CARPETA EN EL DIRECTORIO DE MATLAB EN FORMATO .mat**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directorio donde se guardara la matriz compleja de la VSC estimada en formato .mat\n",
    "mat_dir = 'D:/TT/Memoria/waveletycnn/codigo_matlab/codigo_fuente/coefs_vsc_predicted'\n",
    "os.makedirs(mat_dir, exist_ok=True) # crear directorio \"mat_dir\" si no existe\n",
    "\n",
    "# Extraer el número como cadena\n",
    "numero_como_cadena = nombre_archivo_pam_npy.split('_')[-1].split('.')[0]\n",
    "\n",
    "# Nombre que tendra el archivo de la matriz compleja d la VSC estimada .mat. Se concatena el numero del archivo estimado\n",
    "mat_filename = f'matrix_complex_vsc_predicted_{numero_como_cadena}.mat'\n",
    "print(mat_filename)\n",
    "\n",
    "# Ruta completa del archivo .mat\n",
    "mat_path = os.path.join(mat_dir, mat_filename)\n",
    "\n",
    "\n",
    "try:\n",
    "    data = scipy.io.loadmat(mat_path)\n",
    "    print(\"El archivo es un archivo .mat válido.\")\n",
    "    print(data.keys())\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el archivo .mat: {e}\")\n",
    "\n",
    "\n",
    "# Guardar la matriz compleja en un archivo .mat {nombre archivo: contenido archivo}\n",
    "scipy.io.savemat(mat_path, {mat_filename: complex_matrix_vsc})\n",
    "\n",
    "print(f\"Archivo guardado en: {mat_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
